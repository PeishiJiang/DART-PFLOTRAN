{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "The **objective** of this notebook is to present the workflow of conducting data assimilation on [PFLOTRAN](https://www.pflotran.org/) by using [DART](https://www.image.ucar.edu/DAReS/DART/). Briefly, the procedures are as follows:\n",
    "1. [x] [Configuration](#parameter): define directories, file locations, and other parameters\n",
    "- [x] [PFLOTRAN preparation](#pflotran_prepare): generate PFLOTRAN input files\n",
    "- [x] [PFLOTRAN model spin-up](#pflotran_spinup): conduct model spin-up\n",
    "- [x] [DART files preparation](#dart_prepare): add new DART quantities, prepare DART input namelists, prepare DART prior data, prepare observations in DART format, and check ```model_mod``` interface\n",
    "- [x] [Generate all the executable files](#dart_executables): generate all the executables, convert observations in DART format, check ```model_mod``` interface, and test the filter\n",
    "- [ ] [Run DART and PFLOTRAN](#run_dart_pflotran): run the shell script for integrating DART filter and PFLOTRAN model\n",
    "\n",
    "Here, we perform inverse modeling on a 1D thermal model for illustration. The model assimilates temperature observation to update its parameters (i.e., flow flux, porosity, and thermal conductivity). For now, the ensemble Kalman filter (EnKF) is used for assimilation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='parameter'></a>\n",
    "# Step 1: Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import shutil\n",
    "import pickle\n",
    "import f90nml\n",
    "from math import floor\n",
    "from datetime import datetime, timedelta\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****************\n",
    "**Define the locations of MPI, PFLOTRAN, application folder and DART-PFLOTRAN interface folder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# MPI settings\n",
    "mpi_exe  = '/usr/local/bin/mpirun'  # The location of mpirun\n",
    "ncore_da = 1                        # The number of MPI cores used for DART\n",
    "ncore_pf = 1                        # The number of MPI cores used for PFLOTRAN\n",
    "\n",
    "# PFLOTRAN executable\n",
    "pflotran_exe  = '/Users/jian449/Codes/pflotran/src/pflotran/pflotran'\n",
    "\n",
    "# Main directory names\n",
    "temp_app_dir = os.path.abspath(\"../template\" )          # The template for application folder\n",
    "app_dir      = os.path.abspath(\"../1dthermal\")          # The application folder name\n",
    "dart_dir     = os.path.abspath(\"../../../../\")\n",
    "dart_pf_dir  = os.path.join(dart_dir, \"models/pflotran\")     # The dart pflotran utitlity folder name\n",
    "\n",
    "# configs = {}\n",
    "configs = f90nml.namelist.Namelist()\n",
    "configs[\"main_dir_cfg\"] = {\"app_dir\": app_dir, \"dart_dir\": dart_dir, \"dart_pf_dir\": dart_pf_dir}\n",
    "configs[\"exe_cfg\"]      = {\"pflotran_exe\": pflotran_exe, \"mpi_exe\": mpi_exe, \n",
    "                           \"ncore_pf\": ncore_pf, \"ncore_da\": ncore_da}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****************\n",
    "**Generate the application directory if it does not exit**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Create the application directory if it does not exists\n",
    "if not os.path.isdir(app_dir):\n",
    "    shutil.copytree(temp_app_dir, app_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****************\n",
    "**Load all the required file paths/names from ```file_paths.nml```**\n",
    "\n",
    "```file_paths.nml``` defines the relative locations of all the files (e.g., utility files, shell scripts, data files, etc) used by this application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sys.path.append(dart_pf_dir)\n",
    "from utils.read_filepaths_nml import read_filepaths_nml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dirs_cfg, files_cfg      = read_filepaths_nml(app_dir=app_dir, dart_pf_dir=dart_pf_dir)\n",
    "configs[\"other_dir_cfg\"] = dirs_cfg\n",
    "configs[\"file_cfg\" ]     = files_cfg\n",
    "config_file              = files_cfg[\"config_file\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****************\n",
    "**Specify the following types of variables used in DART**\n",
    "- the observation data to be assimilated\n",
    "- the PFLOTRAN parameters to be analyzed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Observation data to be assimilated\n",
    "obs_set  = ['TEMPERATURE']\n",
    "# The PFLOTRAN parameters to be analyzed\n",
    "para_set = ['FLOW_FLUX','POROSITY','THERMAL_CONDUCTIVITY']\n",
    "\n",
    "configs[\"obspara_set_cfg\"] = {\"obs_set\": obs_set, \"para_set\": para_set}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****************\n",
    "**Specify the temporal information**\n",
    "- model spinup time/start time\n",
    "- the map between the begin of observation assimilation and model start time\n",
    "- the list of model time or the list of starting assimilation time (starting from zero)\n",
    "\n",
    "**note that** model start time is considered after the spinup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "time_cfg = {}\n",
    "# Model spinup length\n",
    "time_cfg[\"spinup_length\"]  = 0.5    # spinup time (day)\n",
    "time_cfg[\"is_spinup_done\"] = False  # whether spinup is conducted\n",
    "\n",
    "# Model start time\n",
    "time_cfg[\"current_model_time\"] = 0.     # model start time zero (after spinup)\n",
    "time_cfg[\"model_time_list\"]    = [0.]   # the list of model time\n",
    "\n",
    "# Map between assimilation start time and model start time\n",
    "assim_start = datetime(2017,4,1,0,0,0)\n",
    "time_cfg[\"assim_start\"] = assim_start.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "# The maximum time for observation\n",
    "time_cfg[\"last_obs_time_days\"]    = 0\n",
    "time_cfg[\"last_obs_time_seconds\"] = 1200*2+100\n",
    "time_cfg[\"last_obs_time_size\"] = time_cfg[\"last_obs_time_days\"]+float(time_cfg[\"last_obs_time_seconds\"])/86400. # day\n",
    "\n",
    "# Whether the model time exceeds the last observation\n",
    "time_cfg[\"exceeds_obs_time\"] = time_cfg[\"current_model_time\"] >= time_cfg[\"last_obs_time_size\"]\n",
    "\n",
    "# Save them to configs\n",
    "configs[\"time_cfg\"] = time_cfg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****************\n",
    "**Define the data assimilation configurations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "da_cfg = {}\n",
    "# More need to be added...\n",
    "# And later on, these DA setting can be saved in a txt or pickel file for further loading\n",
    "da_cfg[\"obs_reso\"]  = 300.0  # observation resolution (second)\n",
    "da_cfg[\"nens\"]      = 30     # number of ensembles\n",
    "\n",
    "# Assimilation time window time_step_days+time_step_seconds\n",
    "# Assimilation window\n",
    "da_cfg[\"assim_window_days\"]    = 0     # assimilation time window/step (day)\n",
    "da_cfg[\"assim_window_seconds\"] = 1200  # assimilation time window/step  (second)\n",
    "da_cfg[\"assim_window_size\"] = da_cfg[\"assim_window_days\"]+float(da_cfg[\"assim_window_seconds\"])/86400. # day\n",
    "\n",
    "# Assimilation start and end time\n",
    "da_cfg[\"assim_start_days\"]    = int(floor(time_cfg[\"current_model_time\"]))\n",
    "da_cfg[\"assim_start_seconds\"] = int((time_cfg[\"current_model_time\"] - da_cfg[\"assim_start_days\"])*86400)\n",
    "da_cfg[\"assim_end_days\"]      = int(floor(time_cfg[\"current_model_time\"]+da_cfg[\"assim_window_size\"]))\n",
    "da_cfg[\"assim_end_seconds\"]   = int((time_cfg[\"current_model_time\"]+da_cfg[\"assim_window_size\"] - \n",
    "                                     da_cfg[\"assim_end_days\"])*86400-1)\n",
    "\n",
    "# Save them to configs\n",
    "configs[\"da_cfg\"] = da_cfg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****************\n",
    "**Save all the configurations in pickle**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Save it in a temperory pickle file or namelist???\n",
    "# with open(config_file, 'wb') as f:\n",
    "#     pickle.dump(configs, f)\n",
    "configs.write(config_file, force=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='pflotran_prepare'></a>\n",
    "# Step 2: PFLOTRAN preparation\n",
    "*Here, we use Kewei's 1D thermal model as an example for generating PFLOTRAN input card and parameter.h5.*\n",
    "\n",
    "In this section, the following procedures are performed:\n",
    "- generate PFLOTRAN input deck file ```PFLOTRAN.in```\n",
    "- generate the parameter files in HDF 5, ```parameter_prior.h5```, used by PFLOTRAN input deck file\n",
    "\n",
    "**Note that**\n",
    "- ```PFLOTRAN.in``` for each DA scenario should be prepared by users.\n",
    "\n",
    "**Run code**\n",
    "- Run: ```prepare_pflotran_input.py```\n",
    "- Code input arguments (loaded from the configuration file):\n",
    "    - <span style=\"background-color:lightgreen\">pflotran_in</span>: filename for ```pflotran.in```\n",
    "    - <span style=\"background-color:lightgreen\">pflotran_para</span>: filename for ```parameter_prior.h5```\n",
    "    - <span style=\"background-color:lightgreen\">obs_resolution, obs_error, nens, spinup_length, spinup</span>: data assimilation settings (i.e., observation timestep, observation error, number of ensemble, whether it is spinup, **to be revised**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "prep_pflotran_input, pflotran_in = files_cfg[\"prep_pflotran_input_file\"], files_cfg[\"pflotran_in_file\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%script bash -s \"$prep_pflotran_input\" \"$config_file\"\n",
    "python $1 $2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%script bash -s \"$pflotran_in\"\n",
    "cat $1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='pflotran_spinup'></a>\n",
    "# Step 3: PFLOTRAN model spin-up\n",
    "Take in the ```pflotran.in``` and ```parameter.h5``` files and conduct the model spin-up by running ```pflotran.sh``` file. The ```pflotran.sh``` is a simple shell script executing ensemble simulation of PFLOTRAN by using MPI.\n",
    "\n",
    "**Run the code**\n",
    "- Run: ```prepare_pflotran_inpara.py```\n",
    "- Code input arguments (loaded from the configuration file):\n",
    "    - <span style=\"background-color:lightgreen\">pflotran_exe</span>: location of the executable PFLOTRAN\n",
    "    - <span style=\"background-color:lightgreen\">pflotran_in</span>: filename for ```pflotran.in```\n",
    "    - <span style=\"background-color:lightgreen\">pflotran_out_dir</span>: directory of PFLOTRAN output\n",
    "    - <span style=\"background-color:lightgreen\">nens</span>: number of ensemble\n",
    "    - <span style=\"background-color:lightgreen\">mpi_exe, ncore</span>: location of mpirun and number of cpu cores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pflotran_sh, pflotran_out_dir = files_cfg[\"pflotran_sh_file\"], dirs_cfg[\"pflotran_out_dir\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%script bash -s \"$pflotran_sh\" \"$config_file\"\n",
    "$1 $2\n",
    "# %%script bash -s \"$pflotran_sh\" \"$pflotran_exe\" \"$pflotran_in\" \"$pflotran_in_dir\" \"$pflotran_out_dir\" \"$nens\" \"$mpi_exe\" \"$ncore_pf\"\n",
    "# $1 $2 $3 $4 $5 $6 $7 $8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****************\n",
    "**Once the model spinup finishes, modify the corresponding configuration entry**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs[\"time_cfg\"][\"is_spinup_done\"] = True\n",
    "configs.write(config_file, force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# %%script bash -s \"$pflotran_out_dir\"\n",
    "# cd $1\n",
    "# ls *.h5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='dart_prepare'></a>\n",
    "# Step 4: DART files preparation\n",
    "In this section, the following procedures are performed:\n",
    "- generate the template for DART generic variable quantity files (i.e., ```DEFAULT_obs_kind_mod.F90``` and ```obs_def_pflotran_mod.f90```);\n",
    "- generate the DART input namelists;\n",
    "- generate DART prior NetCDF data ```prior_ensemble_[ENS].nc``` from PFLOTRAN's parameter and outputs;\n",
    "- generate DART posterior NetCDF files (*sharing the same variable names and dimensions as the prior NetCDF files but without the data values*);\n",
    "- convert the observation file to DART observation format;\n",
    "- check ```model_mod.F90``` based on current setting by using the ```check_model_mod``` provided by DART."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='dart_generic_prepare'></a>\n",
    "## Generate the templates for DART generic variable quantity files\n",
    "- Run: ```list2dartqty.py``` to sequentially generate\n",
    "    - a mapping between PFLOTRAN variales and DART generic quantities in ```obs_def_pflotran_mod.F90```\n",
    "    - the default DART generic quantity definition file ```DEFAULT_obs_kind_mod.F90```\n",
    "- Code input arguments:\n",
    "    - <span style=\"background-color:lightgreen\">obs_type</span>: filename for ```DEFAULT_obs_kind_mod.F90```\n",
    "    - <span style=\"background-color:lightgreen\">def_obs_kind</span>: filename for ```obs_def_pflotran_mod.F90```\n",
    "    - <span style=\"background-color:lightgreen\">pflotran_parastate_set</span>: a list of variables required to be assimilated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "to_dartqty, obs_type_file = files_cfg[\"to_dartqty_file\"], files_cfg[\"obs_type_file\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%script bash -s \"$to_dartqty\" \"$config_file\"\n",
    "python $1 $2 $3 $4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%script bash -s \"$obs_type_file\"\n",
    "cat $1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate  DART input namelists in ```input.nml```\n",
    "\n",
    "The ```input.nml``` file is generated based on a template ```input.nml.template``` by modifying the following namelist entries:\n",
    "\n",
    "```input.nml.template``` $\\rightarrow$ ```input.nml```\n",
    "\n",
    "|filter_nml|obs_kind_nml|preprocess_nml|model_nml|convertnc_nml|\n",
    "|:--:|:--:|:--:|:--:|:--:|\n",
    "| input_state_file_list, output_state_file_list, ens_size, async, adv_ens_command, obs_sequence_in_name | assimilate_these_obs_types | input_files, input_obs_kind_mod_file | time_step_days, time_step_seconds, nvar, var_names, template_file, var_qtynames | netcdf_file, out_file |\n",
    "\n",
    "**Namelists from DART**\n",
    "- [filter_nml](https://www.image.ucar.edu/DAReS/DART/Manhattan/assimilation_code/modules/assimilation/filter_mod.html): namelist of the main module for driving ensemble filter assimilations\n",
    "- [obs_kind_nml](https://www.image.ucar.edu/DAReS/DART/Manhattan/assimilation_code/modules/observations/obs_kind_mod.html#Namelist): namelist for controling what observation types are to be assimilated\n",
    "- [preprocess_nml](https://www.image.ucar.edu/DAReS/Codes/DART/manhattan/assimilation_code/programs/preprocess/preprocess): namelist of the DART-supplied preprocessor program which creates observation kind and observation definition modules from a set of other specially formatted Fortran 90 files\n",
    "\n",
    "**Self-defined namelists**\n",
    "- model_nml: a self-defined namelist for providing the basic information in the model\n",
    "    - time_step_days, time_step_seconds: the assimilation time window\n",
    "    - template_file: the template prior NetCDF file for ```model_mod.F90``` to digest the spatial information of the model\n",
    "    - var_names: the original variable names\n",
    "    - var_qtynames: the corresponding DART variable quantities\n",
    "    - nvar: the number of variables\n",
    "- convertnc_nml: a self-defined namelist for providing the NetCDF observation file name and the DART observation file name used in ```convert_nc.f90```\n",
    "    - netcdf_file: the location of the NetCDF file containing the observation data\n",
    "    - out_file: the location of the DART observation file\n",
    "\n",
    "**Note that**\n",
    "- There are more namelists or other items in the above namelist in input.nml.template. Users can edit the below python dictionary ```inputnml``` to include their modifications.\n",
    "- Users can also include more namelists provided by DART by modifying ```inputnml```."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***************\n",
    "**Assemble all the namelists in input.nml**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Parameters for different namelists in input.nml\n",
    "filter_nml = {\"input_state_file_list\":files_cfg[\"dart_input_list_file\"],\n",
    "              \"output_state_file_list\":files_cfg[\"dart_output_list_file\"],\n",
    "              \"ens_size\":da_cfg[\"nens\"],\n",
    "              \"num_output_state_members\":da_cfg[\"nens\"],\n",
    "              \"obs_sequence_in_name\":files_cfg[\"obs_dart_file\"]}\n",
    "#               \"obs_window_days\":obs_window_days,\n",
    "#               \"obs_window_seconds\":obs_window_seconds}\n",
    "obs_kind_nml = {\"assimilate_these_obs_types\":obs_set}\n",
    "model_nml = {\"time_step_days\":da_cfg[\"assim_window_days\"],\n",
    "             \"time_step_seconds\":da_cfg[\"assim_window_seconds\"],\n",
    "             \"nvar\":len(obs_set)+len(para_set),\n",
    "             \"var_names\":obs_set+para_set,\n",
    "             \"template_file\":files_cfg[\"dart_prior_template_file\"],\n",
    "             \"var_qtynames\":['QTY_PFLOTRAN_'+v for v in obs_set]+['QTY_PFLOTRAN_'+v for v in para_set]}\n",
    "preprocess_nml = {\"input_files\":files_cfg[\"obs_type_file\"],\n",
    "                  \"input_obs_kind_mod_file\":files_cfg[\"def_obs_kind_file\"]}\n",
    "convertnc_nml = {\"netcdf_file\": files_cfg[\"obs_nc_file\"],\n",
    "                 \"out_file\": files_cfg[\"obs_dart_file\"],\n",
    "                 \"obs_start_day\": da_cfg[\"assim_start_days\"],\n",
    "                 \"obs_start_second\": da_cfg[\"assim_start_seconds\"],\n",
    "                 \"obs_end_day\": da_cfg[\"assim_end_days\"],\n",
    "                 \"obs_end_second\":da_cfg[\"assim_end_seconds\"]}\n",
    "modelmodcheck_nml = {\"input_state_files\": files_cfg[\"dart_prior_template_file\"]}\n",
    "inputnml = {\"filter_nml\":filter_nml,\n",
    "            \"obs_kind_nml\":obs_kind_nml,\n",
    "            \"model_nml\":model_nml,\n",
    "            \"preprocess_nml\":preprocess_nml,\n",
    "            \"convert_nc_nml\":convertnc_nml,\n",
    "            \"model_mod_check_nml\":modelmodcheck_nml}\n",
    "\n",
    "\n",
    "configs[\"inputnml_cfg\"] = inputnml\n",
    "\n",
    "# Save the configurations\n",
    "configs.write(config_file, force=True)\n",
    "# with open(config_pickle, 'wb') as f:\n",
    "#     pickle.dump(configs, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***************\n",
    "**Run the code**\n",
    "- Run: ```prepare_inputnml.py```\n",
    "- Code input arguments:\n",
    "    - <span style=\"background-color:lightgreen\">input_nml</span>: the ```input.nml``` namelist file\n",
    "    - <span style=\"background-color:lightgreen\">input_nml_dict</span>: the ```inputnml.p``` pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "prep_inputnml = files_cfg[\"prep_inputnml_file\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%script bash -s  \"$prep_inputnml\" \"$config_file\"\n",
    "python $1 $2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert the model output to DART prior NetCDF and  generate the preliminary DART posterior NetCDF file\n",
    "- The structure of ```prior_ensemble_[ENS].nc``` and ```posterior_ensemble_[ENS].nc``` files (```[ENS]``` refers to the ensemble number):\n",
    "\n",
    "| NetCDF dimensions |                      NetCDF variables                      |\n",
    "|:-----------------:|:----------------------------------------------------------:|\n",
    "| time: 1           | time: shape(time)                                          |\n",
    "| x_location: nx    | x_location: shape(x_location)                              |\n",
    "| y_location: ny    | y_location: shape(y_location)                              |\n",
    "| z_location: nz    | z_location: shape(z_location)                              |\n",
    "| member: 1         | member: shape(member)                                      |\n",
    "|                   | physical variable: shape(x_location,y_location,z_location) |\n",
    "\n",
    "**Note that** \n",
    "- required by DART, each ```prior_R[ENS].nc``` file only includes the state/parameter values of one ensemble member at one given time. \n",
    "- For the time, we set the initial time as 0, with time units converted *day* (requied by DART's ```read_model_time``` subroutine). \n",
    "- Also, it is different from the definition for the [observation NetCDF](#observationconvertion), because ```prior_R[ENS].nc``` aims for the structured cartesian grids while the observation NetCDF aims for a general case.\n",
    "\n",
    "**Run the code**\n",
    "- Run: ```prepare_prior_nc.py``` to generate \n",
    "    - the DART prior input file ```prior_ensemble_[ENS].nc```\n",
    "    - the DART posterior output file ```prior_ensemble_[ENS].nc``` (*sharing the same variable names and dimensions as the prior files but without the variable values*)\n",
    "    - the prior template file (copied from ```prior_ensemble_1.nc```) used by ```input.nml```\n",
    "    - the dart_input_list and dart_output_list used by DART\n",
    "- Code input arguments:\n",
    "    - <span style=\"background-color:lightgreen\">pflotran_out</span>: filename ```R[ENS].h5``` from PFLOTRAN model output\n",
    "    - <span style=\"background-color:lightgreen\">pflotran_para</span>: pflotran parameter HDF file ```parameter.h5```\n",
    "    - <span style=\"background-color:lightgreen\">dart_prior_nc</span>: filename ```prior_R[ENS].nc``` for the prior input file for DART\n",
    "    - <span style=\"background-color:lightgreen\">dart_input_list</span>: filename for recording the list of dart_prior_nc\n",
    "    - <span style=\"background-color:lightgreen\">nens</span>: number of ensemble\n",
    "    - <span style=\"background-color:lightgreen\">spinup</span>: whether it is spinup (if yes, the time is set to zero; otherwise, the time is read from ```R[ENS].h5```)\n",
    "    - <span style=\"background-color:lightgreen\">pflotran_parastate_set</span>: a list of variables to be assimilated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_prior_nc, dart_prior_template = files_cfg[\"prep_prior_nc_file\"], files_cfg[\"dart_prior_template_file\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%script bash -s \"$prep_prior_nc\" \"$config_file\"\n",
    "python $1 $2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%script bash -s \"$dart_prior_template\"\n",
    "ncdump -h $1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='observationconvertion'></a>\n",
    "## Prepare the observation conversion to DART observation format\n",
    "In this section, we prepare the process of converting the observation data to DART format. We first convert observation data in raw format into NetCDF format. Then, a fortran script is prepared for the conversion from the NetCDF to to DART format. The structure of NetCDF file for recording observation file.\n",
    "\n",
    "| NetCDF dimensions |           NetCDF variables          |\n",
    "|:-----------------:|:-----------------------------------:|\n",
    "| time: 1           | time: shape(time)                   |\n",
    "| location: nloc    | location: shape(location)           |\n",
    "|                   | physical variable: shape(time,nloc) |\n",
    "\n",
    "**Note that** \n",
    "- if the time calendar follows *gregorian*, the time unit should be entered as ```seconds since YYYY-MM-DD HH:MM:SS```. Otherwise, put the time calender as *None* and time unit as ```second``` (make sure convert your measurement times to seconds)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***************\n",
    "**Convert the raw csv temperature observations to NetCDF file**\n",
    "- Run: ```csv2nc.py```\n",
    "- Code input arguments:\n",
    "    - <span style=\"background-color:lightgreen\">obs_original</span>: filename for the original observed temperature file\n",
    "    - <span style=\"background-color:lightgreen\">obs_nc</span>: filename for the observation NetCDF file\n",
    "    - <span style=\"background-color:lightgreen\">assim_start_str</span>: the reference time to set zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_to_nc, obs_nc = files_cfg[\"csv_to_nc_file\"], files_cfg[\"obs_nc_file\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%script bash -s \"$csv_to_nc\" \"$config_file\"\n",
    "python $1 $2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%script bash -s \"$obs_nc\"\n",
    "ncdump -h $1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***************\n",
    "**Prepare the ```convert_nc.f90``` based on the list of observation variables**\n",
    "- Run: ```prepare_convert_nc.py```\n",
    "- Code input arguments:\n",
    "    - <span style=\"background-color:lightgreen\">obs_nc</span>: filename for the observation NetCDF file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_convert_nc, convert_nc_file = files_cfg[\"prep_convert_nc_file\"], files_cfg[\"convert_nc_file\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%script bash -s \"$prep_convert_nc\" \"$config_file\"\n",
    "python $1 $2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%script bash -s \"$convert_nc_file\"\n",
    "head $1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='dart_executables'></a>\n",
    "# Step 5: Generate all the executable files\n",
    "Now, we compile all the executables from ```mkmf_*```. The following executables are generated here:\n",
    "- ```preprocess```: for preprocessing the [prepared DART generic variable quantity files prepared](#dart_generic_prepare)\n",
    "- ```convert_nc```: for [converting the observations from NetCDF to DART format](#observationconvertion)\n",
    "- ```model_mod_check```: for checking ```model_mod.F90``` interface file\n",
    "- ```filter```: for conducting the [DART data assimilation](https://www.image.ucar.edu/DAReS/DART/Manhattan/assimilation_code/programs/filter/filter.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the executables\n",
    "- Run: ```quickbuild.csh```\n",
    "- Code input arguments:\n",
    "    - <span style=\"background-color:lightgreen\">app_work_dir</span>: location of the application work folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dart_work_dir, app_work_dir = dirs_cfg[\"dart_work_dir\"], dirs_cfg[\"app_work_dir\"]\n",
    "quickbuild = files_cfg[\"quickbuild_csh\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# %%script bash -s \"$dart_work_dir\" \"$quickbuild\" \"$app_work_dir\"\n",
    "# cd $1\n",
    "# csh $2 $3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert the observation file in NetCDF to DART format\n",
    "- Run: ```convert_nc```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_nc, obs_dart = files_cfg[\"convert_nc_exe\"], files_cfg[\"obs_dart_file\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%script bash -s \"$app_work_dir\" \"$convert_nc\"\n",
    "cd $1\n",
    "$2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%script bash -s \"$obs_dart\"\n",
    "head -n100 $1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check ```model_mod.F90``` interface file\n",
    "- Run: ```model_mod_check```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mod_check = files_cfg[\"model_mod_check_exe\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%script bash -s \"$app_work_dir\" \"$model_mod_check\"\n",
    "cd $1\n",
    "$2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='run_dart_pflotran'></a>\n",
    "# Step 6: Run DART and PFLOTRAN\n",
    "In this section, run the shell script to couple DART and PFLOTRAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dart_work_dir = dirs_cfg[\"dart_work_dir\"]\n",
    "inputnml_file = files_cfg[\"input_nml_file\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%script bash -s \"$dart_work_dir\" \"$inputnml_file\" \"$config_file\"\n",
    "cd $1\n",
    "csh run_DART_PFLOTRAN.csh $2 $3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test ```update_confignml_time.py```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update_confignml_time, inputnml_file = files_cfg[\"update_confignml_time_file\"], files_cfg[\"input_nml_file\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%script bash -s \"$update_confignml_time\" \"$config_file\"\n",
    "# python $1 $2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test ```filter```\n",
    "- Run: ```filter```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter_exe = files_cfg[\"filter_exe\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# %%script bash -s \"$app_work_dir\" \"$filter_exe\"\n",
    "# cd $1\n",
    "# $2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "261.79px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 122.712818,
   "position": {
    "height": "40px",
    "left": "1066.08px",
    "right": "20px",
    "top": "82px",
    "width": "250px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
