{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "The **objective** of this notebook is to present the workflow of conducting data assimilation on [PFLOTRAN](https://www.pflotran.org/) by using [DART](https://www.image.ucar.edu/DAReS/DART/). Briefly, the procedures are as follows:\n",
    "1. [x] [Configuration](#parameter): define directories, file locations, and other parameters\n",
    "- [x] [PFLOTRAN preparation](#pflotran_prepare): generate PFLOTRAN input files\n",
    "- [x] [PFLOTRAN model spin-up](#pflotran_spinup): conduct model spin-up\n",
    "- [x] [DART files preparation](#dart_prepare): add new DART quantities, prepare DART input namelists, prepare DART prior data, prepare observations in DART format, and check ```model_mod``` interface\n",
    "- [x] [Generate all the executable files](#dart_executables): generate all the executables, convert observations in DART format, check ```model_mod``` interface, and test the filter\n",
    "- [x] [Run DART and PFLOTRAN](#run_dart_pflotran): run the shell script for integrating DART filter and PFLOTRAN model\n",
    "\n",
    "Here, we perform inverse modeling on a 1D thermal model for illustration. The model assimilates temperature observation to update its parameters (i.e., flow flux, porosity, and thermal conductivity). For now, the ensemble Kalman filter (EnKF) is used for assimilation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='parameter'></a>\n",
    "# Step 1: Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 882,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import time\n",
    "import shutil\n",
    "import pickle\n",
    "import f90nml\n",
    "from math import floor\n",
    "from datetime import datetime, timedelta\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****************\n",
    "**Define the locations of MPI, PFLOTRAN, application folder and DART-PFLOTRAN interface folder**\n",
    "\n",
    "It is suggested that <span style=\"background-color:lightgreen\">mpi_exe</span> is defined based on the mpi utility (e.g., mpirun) installed by PFLOTRAN.\n",
    "\n",
    "**Important:** You must make sure the <span style=\"background-color:lightgreen\">mpi_exe</span> has the same MPI system as the settings ```MPIFC``` and ```MPILD``` in ```mkmf.template```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 883,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MPI settings\n",
    "mpi_exe_da  = '/usr/local/bin/mpirun'  # The location of mpirun\n",
    "# mpi_exe_da  = '/Users/jian449/Codes/petsc/arch-darwin-c-opt/bin/mpirun'\n",
    "mpi_exe_pf  = '/Users/jian449/Codes/petsc/arch-darwin-c-opt/bin/mpirun'\n",
    "ncore_da = 1                        # The number of MPI cores used by DART\n",
    "ncore_pf = 1                        # The number of MPI cores used by PFLOTRAN\n",
    "ngroup_pf= 1                        # The number of group used by stochastic running in PFLOTRAN\n",
    "\n",
    "# PFLOTRAN executable\n",
    "pflotran_exe  = '/Users/jian449/Codes/pflotran/src/pflotran/pflotran'\n",
    "\n",
    "# Main directory names\n",
    "temp_app_dir = \"/Users/jian449/Codes/DART/manhattan/models/pflotran/applications/template\"          # The template for application folder\n",
    "app_dir      = \"/Users/jian449/Codes/DART/manhattan/models/pflotran/applications/1dthermal\"          # The application folder name\n",
    "dart_dir     = \"/Users/jian449/Codes/DART/manhattan/\"\n",
    "dart_pf_dir  = \"/Users/jian449/Codes/DART/manhattan/models/pflotran\"     # The dart pflotran utitlity folder name\n",
    "# temp_app_dir = os.path.abspath(\"../template\")          # The template for application folder\n",
    "# app_dir      = os.path.abspath(\"../1dthermal/\")          # The application folder name\n",
    "# dart_dir     = os.path.abspath(\"../../../../\")\n",
    "# dart_pf_dir  = os.path.join(dart_dir, \"models/pflotran\")     # The dart pflotran utitlity folder name\n",
    "\n",
    "# configs = {}\n",
    "configs = f90nml.namelist.Namelist()\n",
    "configs[\"main_dir_cfg\"] = {\"app_dir\": app_dir, \"dart_dir\": dart_dir, \"dart_pf_dir\": dart_pf_dir}\n",
    "configs[\"exe_cfg\"]      = {\"pflotran_exe\": pflotran_exe, \"mpi_exe_da\": mpi_exe_da, \"mpi_exe_pf\": mpi_exe_pf, \n",
    "                           \"ncore_pf\": ncore_pf, \"ncore_da\": ncore_da, \"ngroup_pf\": ngroup_pf}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****************\n",
    "**Generate the application directory if it does not exit**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 884,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the application directory if it does not exists\n",
    "if not os.path.isdir(app_dir):\n",
    "    shutil.copytree(temp_app_dir, app_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****************\n",
    "**Load all the required file paths/names from ```file_paths.nml```**\n",
    "\n",
    "```file_paths.nml``` defines the relative locations of all the files (e.g., utility files, shell scripts, data files, etc) used by this application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 885,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(dart_pf_dir)\n",
    "from utils.read_filepaths_nml import read_filepaths_nml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 886,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs_cfg, files_cfg      = read_filepaths_nml(app_dir=app_dir, dart_pf_dir=dart_pf_dir)\n",
    "configs[\"other_dir_cfg\"] = dirs_cfg\n",
    "configs[\"file_cfg\" ]     = files_cfg\n",
    "config_file              = files_cfg[\"config_file\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****************\n",
    "**Specify the following types of variables used in DART**\n",
    "- the observation data to be assimilated\n",
    "- the PFLOTRAN parameters to be analyzed\n",
    "- the statistics of the parameters: (1) the value range; (2) the mean and std for randomly sampling; (3) the distribution to be sampled (i.e., normal, nd uniform distributions).\n",
    "- The list of parameters whose prior would be resampled based on the mean of the corresponding posterior at the previous time step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 887,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observation data to be assimilated\n",
    "obs_set  = ['TEMPERATURE']\n",
    "\n",
    "# The PFLOTRAN parameters to be analyzed\n",
    "para_set = ['FLOW_FLUX','POROSITY','THERMAL_CONDUCTIVITY']\n",
    "# para_set = ['FLOW_FLUX']\n",
    "\n",
    "# The statistics of the parameters\n",
    "# The index order follows para_set\n",
    "para_min_set  = [-5.0, 0.01, 0.5]  # The minimum values (-99999 means no lower bound limit)\n",
    "para_max_set  = [5.0, 0.7, 2.5]  # The maximum values (99999 means no upper bound limit)\n",
    "para_mean_set = [0.0, 0.3, 1.5]  # The mean values\n",
    "para_std_set  = [0.5, 0.1, 0.5]  # The standard deviation values\n",
    "para_dist_set = [\"normal\", \"normal\", \"normal\"]  # The assumed distribution to be sampled\n",
    "# para_min_set  = [-10.0]  # The minimum values (-99999 means no lower bound limit)\n",
    "# para_max_set  = [10.0]  # The maximum values (99999 means no upper bound limit)\n",
    "# para_mean_set = [0.0]  # The mean values\n",
    "# para_std_set  = [0.5]  # The standard deviation values\n",
    "# para_dist_set = [\"uniform\"]  # The assumed distribution to be sampled\n",
    "\n",
    "para_resampled_set = ['']   # The parameters to be resampled at each time step\n",
    "\n",
    "configs[\"obspara_set_cfg\"] = {\"obs_set\": obs_set, \"para_set\": para_set,\n",
    "                              \"para_min_set\": para_min_set, \"para_max_set\": para_max_set,\n",
    "                              \"para_mean_set\": para_mean_set, \"para_std_set\": para_std_set,\n",
    "                              \"para_dist_set\": para_dist_set, \"para_resampled_set\": para_resampled_set}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****************\n",
    "**Specify the spatial domains of the observation data to be assimilated**\n",
    "\n",
    "The limits of x, y, and z are bounded by the minimum and maximum boundaries through (min, max). If the limit is not specified, -99999 and 99999 are assigned for the lower and upper bounds, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 888,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_space_xlimit = [-99999, 99999]\n",
    "obs_space_ylimit = [-99999, 99999]\n",
    "obs_space_zlimit = [-0.5, -0.04]\n",
    "configs[\"obs_space_cfg\"] = {\"obs_space_xlimit\": obs_space_xlimit, \"obs_space_ylimit\": obs_space_ylimit,\n",
    "                            \"obs_space_zlimit\": obs_space_zlimit}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****************\n",
    "**Specify the temporal information**\n",
    "- model spinup time/start time\n",
    "- the map between the begin of observation assimilation and model start time\n",
    "- the list of model time or the list of starting assimilation time (starting from zero)\n",
    "\n",
    "**note that** model start time is considered after the spinup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 889,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_cfg = {}\n",
    "# Model spinup length\n",
    "time_cfg[\"spinup_length\"]  = 0.5    # spinup time (day)\n",
    "time_cfg[\"is_spinup_done\"] = False  # whether spinup is conducted\n",
    "\n",
    "# Model start time\n",
    "time_cfg[\"current_model_time\"] = 0.     # model start time zero (after spinup)\n",
    "time_cfg[\"model_time_list\"]    = [0.]   # the list of model time\n",
    "\n",
    "# Map between assimilation start time and model start time\n",
    "obs_start   = datetime(2017,4,1,0,0,0) \n",
    "assim_start = obs_start + timedelta(days=time_cfg[\"spinup_length\"]) # assimilation time should be after the model spinup\n",
    "time_cfg[\"assim_start\"] = assim_start.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "# The maximum time for observation\n",
    "time_cfg[\"first_obs_time_days\"]    = 0\n",
    "time_cfg[\"first_obs_time_seconds\"] = 0\n",
    "time_cfg[\"first_obs_time_size\"] = time_cfg[\"first_obs_time_days\"]+float(time_cfg[\"first_obs_time_seconds\"])/86400. # day\n",
    "time_cfg[\"last_obs_time_days\"]    = 0\n",
    "time_cfg[\"last_obs_time_seconds\"] = 1800*100\n",
    "time_cfg[\"last_obs_time_size\"] = time_cfg[\"last_obs_time_days\"]+float(time_cfg[\"last_obs_time_seconds\"])/86400. # day\n",
    "\n",
    "# Whether the model time exceeds the last observation\n",
    "time_cfg[\"exceeds_obs_time\"] = time_cfg[\"current_model_time\"] >= time_cfg[\"last_obs_time_size\"]\n",
    "\n",
    "# Save them to configs\n",
    "configs[\"time_cfg\"] = time_cfg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****************\n",
    "**Define the data assimilation configurations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 890,
   "metadata": {},
   "outputs": [],
   "source": [
    "da_cfg = {}\n",
    "# More need to be added...\n",
    "# And later on, these DA setting can be saved in a txt or pickel file for further loading\n",
    "da_cfg[\"obs_reso\"]  = 300.0      # observation resolution (second)\n",
    "da_cfg[\"nens\"]      = 40         # number of ensembles\n",
    "da_cfg[\"obs_error\"] = 0.01       # the observation error\n",
    "da_cfg[\"obs_error_type\"] = \"relative\" # the type of observation error (i.e., relative and absolute)\n",
    "\n",
    "# Assimilation time window time_step_days+time_step_seconds\n",
    "# Assimilation window\n",
    "da_cfg[\"assim_window_days\"]    = 0     # assimilation time window/step (day)\n",
    "da_cfg[\"assim_window_seconds\"] = 1800  # assimilation time window/step  (second)\n",
    "da_cfg[\"assim_window_size\"] = da_cfg[\"assim_window_days\"]+float(da_cfg[\"assim_window_seconds\"])/86400. # day\n",
    "\n",
    "# Assimilation start and end time\n",
    "da_cfg[\"assim_start_days\"]    = int(floor(time_cfg[\"current_model_time\"]))\n",
    "da_cfg[\"assim_start_seconds\"] = int((time_cfg[\"current_model_time\"] - da_cfg[\"assim_start_days\"])*86400)\n",
    "da_cfg[\"assim_end_days\"]      = int(floor(time_cfg[\"current_model_time\"]+da_cfg[\"assim_window_size\"]))\n",
    "da_cfg[\"assim_end_seconds\"]   = int((time_cfg[\"current_model_time\"]+da_cfg[\"assim_window_size\"] - \n",
    "                                     da_cfg[\"assim_end_days\"])*86400-1)\n",
    "\n",
    "# Save them to configs\n",
    "configs[\"da_cfg\"] = da_cfg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****************\n",
    "**Save all the configurations in pickle**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 891,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save it in a temperory pickle file or namelist???\n",
    "# with open(config_file, 'wb') as f:\n",
    "#     pickle.dump(configs, f)\n",
    "configs.write(config_file, force=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='pflotran_prepare'></a>\n",
    "# Step 2: PFLOTRAN preparation\n",
    "*Here, we use Kewei's 1D thermal model as an example for generating PFLOTRAN input card and parameter.h5.*\n",
    "\n",
    "In this section, the following procedures are performed:\n",
    "- generate PFLOTRAN input deck file ```PFLOTRAN.in```\n",
    "- generate the parameter files in HDF 5, ```parameter_prior.h5```, used by PFLOTRAN input deck file\n",
    "\n",
    "**Note that**\n",
    "- ```PFLOTRAN.in``` for each DA scenario should be prepared by users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 892,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_pflotran_inputdeck, pflotran_in = files_cfg[\"prep_pflotran_inputdeck_file\"], files_cfg[\"pflotran_in_file\"]\n",
    "prep_pflotran_parameterprior = files_cfg[\"prep_pflotran_para_file\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****************\n",
    "**Generate the ensembles of PFLOTRAN prior**\n",
    "\n",
    "**Run code**\n",
    "- Run: ```prepare_pflotran_parameterprior.py```\n",
    "- Code input arguments (loaded from the configuration file):\n",
    "    - <span style=\"background-color:lightgreen\">pflotran_para</span>: filename for ```parameter_prior.h5```\n",
    "    - <span style=\"background-color:lightgreen\">obs_resolution, obs_error, nens, spinup_length, spinup</span>: data assimilation settings (i.e., observation timestep, observation error, number of ensemble, whether it is spinup, **to be revised**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 893,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script bash -s \"$prep_pflotran_parameterprior\" \"$config_file\"\n",
    "python $1 $2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****************\n",
    "**Generate PFLOTRAN input deck file**\n",
    "\n",
    "**Run code**\n",
    "- Run: ```prepare_pflotran_inputdeck.py```\n",
    "- Code input arguments (loaded from the configuration file):\n",
    "    - <span style=\"background-color:lightgreen\">pflotran_in</span>: filename for ```pflotran.in```\n",
    "    - <span style=\"background-color:lightgreen\">pflotran_para</span>: filename for ```parameter_prior.h5```\n",
    "    - <span style=\"background-color:lightgreen\">obs_resolution, obs_error, nens, spinup_length, spinup</span>: data assimilation settings (i.e., observation timestep, observation error, number of ensemble, whether it is spinup, **to be revised**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 894,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished generating the input card for PFLOTRAN...\n"
     ]
    }
   ],
   "source": [
    "%%script bash -s \"$prep_pflotran_inputdeck\" \"$config_file\"\n",
    "python $1 $2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 895,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Description: 1D thermal\n",
      "\n",
      "SIMULATION\n",
      "  SIMULATION_TYPE SUBSURFACE\n",
      "  PROCESS_MODELS\n",
      "    SUBSURFACE_FLOW FLOW\n",
      "      MODE TH\n",
      "#      OPTIONS\n",
      "#\tREVERT_PARAMETERS_ON_RESTART\n",
      "#      /\n",
      "    /\n",
      "  /\n",
      "  CHECKPOINT\n",
      "  /\n",
      "#  RESTART\n",
      "#    FILENAME 1dthermal-restart.chk\n",
      "#    REALIZATION_DEPENDENT\n",
      "#    RESET_TO_TIME_ZERO\n",
      "  /\n",
      "END\n",
      "\n",
      "SUBSURFACE\n",
      "\n",
      "#=========================== solver options ===================================\n",
      "TIMESTEPPER FLOW\n",
      "  TS_ACCELERATION 8\n",
      "  MAX_TS_CUTS 50\n",
      "END\n",
      "\n",
      "TIMESTEPPER TRANSPORT\n",
      "  TS_ACCELERATION 8\n",
      "  MAX_TS_CUTS 50\n",
      "END\n",
      "\n",
      "NEWTON_SOLVER FLOW\n",
      "  MAXIT 20\n",
      "  RTOL 1.d-50\n",
      "  ATOL 1.d-50\n",
      "  STOL 1.e-60\n",
      "  ITOL_UPDATE 1.d0\n",
      "END\n",
      "\n",
      "LINEAR_SOLVER FLOW\n",
      "END\n",
      "\n",
      "NEWTON_SOLVER TRANSPORT\n",
      "  NO_INFINITY_NORM\n",
      "END\n",
      "\n",
      "LINEAR_SOLVER TRANSPORT\n",
      "END\n",
      "\n",
      "\n",
      "#=========================== discretization ===================================\n",
      "GRID\n",
      "  TYPE structured\n",
      "  NXYZ 1 1 64\n",
      "  BOUNDS\n",
      "    0.d0 0.d0 -0.64d0\n",
      "    1.d0 1.d0 0.d0\n",
      "  /\n",
      "END\n",
      "\n",
      "#=========================== fluid properties =================================\n",
      "FLUID_PROPERTY\n",
      "  DIFFUSION_COEFFICIENT 1.d-9\n",
      "END\n",
      "\n",
      "#=========================== material properties ==============================\n",
      "MATERIAL_PROPERTY Alluvium\n",
      "  ID 1\n",
      "  POROSITY 0.43\n",
      "  TORTUOSITY 1.d0\n",
      "  ROCK_DENSITY 2.65d3\n",
      "  CHARACTERISTIC_CURVES default\n",
      "  PERMEABILITY\n",
      "     PERM_ISO 3.86E-11\n",
      "  /\n",
      "  SPECIFIC_HEAT 9.20d2\n",
      "  THERMAL_CONDUCTIVITY_DRY 0.7163971\n",
      "  THERMAL_CONDUCTIVITY_WET 0.93\n",
      "END\n",
      "\n",
      "#=========================== characteristic curves ============================\n",
      "CHARACTERISTIC_CURVES default\n",
      "  DEFAULT\n",
      "/\n",
      "#=========================== output options ===================================\n",
      "OUTPUT\n",
      "\n",
      "  VARIABLES\n",
      "#    LIQUID_SATURATION\n",
      "    LIQUID_PRESSURE\n",
      "#    LIQUID_MOBILITY\n",
      "    TEMPERATURE\n",
      "#    PERMEABILITY\n",
      "  /\n",
      "\n",
      "\n",
      " SNAPSHOT_FILE\n",
      "   PERIODIC TIME 60.0 s\n",
      "   FORMAT HDF5 SINGLE_FILE\n",
      " /\n",
      "\n",
      "\n",
      "#  OBSERVATION_FILE\n",
      "#    TIMES sec 10.0\n",
      "#  /\n",
      "\n",
      "# MASS_BALANCE_FILE\n",
      "#    PERIODIC TIME 5.0d0 min\n",
      "#  /\n",
      "\n",
      "#  VELOCITY_AT_CENTER\n",
      "\n",
      "END\n",
      "\n",
      "#=========================== times ============================================\n",
      "TIME\n",
      "  FINAL_TIME 45000.0 sec\n",
      "  INITIAL_TIMESTEP_SIZE 6.0d1  min\n",
      "  MAXIMUM_TIMESTEP_SIZE 6.0d1 min\n",
      "  MINIMUM_TIMESTEP_SIZE 1.0d-2 sec\n",
      "END\n",
      "\n",
      "#=========================== regions ==========================================\n",
      "REGION all\n",
      "  COORDINATES\n",
      "    0.d0 0.d0 -0.64d0\n",
      "    1.d0 1.d0 0.d0\n",
      "  /\n",
      "END\n",
      "\n",
      "REGION top\n",
      "  FACE TOP\n",
      "  COORDINATES\n",
      "    0.d0 0.d0 0.d0\n",
      "    1.d0 1.d0 0.d0\n",
      "  /\n",
      "END\n",
      "\n",
      "REGION bottom\n",
      "  FACE BOTTOM\n",
      "  COORDINATES\n",
      "    0.d0 0.d0 -0.64d0\n",
      "    1.d0 1.d0 -0.64d0\n",
      "  /\n",
      "END\n",
      "\n",
      "# REGION Obs_1\n",
      "#   COORDINATE 0.5 0.5 -4.0d-2\n",
      "# /\n",
      "\n",
      "\n",
      "# REGION Obs_2\n",
      "#   COORDINATE 0.5 0.5 -2.4d-1\n",
      "# /\n",
      "\n",
      "#=========================== dataset  ===============================\n",
      "DBASE_FILENAME parameter_prior.h5\n",
      "\n",
      "#=========================== observation points ===============================\n",
      "# OBSERVATION\n",
      "#   REGION Obs_1\n",
      "#   VELOCITY\n",
      "# /\n",
      "\n",
      "# OBSERVATION\n",
      "#   REGION Obs_2\n",
      "#   VELOCITY\n",
      "# /\n",
      "\n",
      "\n",
      "#=========================== flow conditions ==================================\n",
      "\n",
      "MINIMUM_HYDROSTATIC_PRESSURE -1.d0\n",
      "\n",
      "FLOW_CONDITION initial\n",
      "  TYPE\n",
      "    PRESSURE HYDROSTATIC\n",
      "    TEMPERATURE dirichlet\n",
      "  /\n",
      "  PRESSURE 101325.d0\n",
      "  TEMPERATURE 2.6700865d0\n",
      "END\n",
      "\n",
      "\n",
      "FLOW_CONDITION flow_top\n",
      "  TYPE\n",
      "    FLUX NEUMANN\n",
      "    TEMPERATURE dirichlet\n",
      " /\n",
      "\n",
      "  FLUX DBASE_VALUE FLOW_FLUX m/day\n",
      "  TEMPERATURE FILE temp_top.dat\n",
      "/\n",
      "\n",
      "\n",
      "FLOW_CONDITION flow_bottom\n",
      "  TYPE\n",
      "    PRESSURE HYDROSTATIC\n",
      "    TEMPERATURE dirichlet\n",
      " /\n",
      "  DATUM 0. 0. 5.\n",
      "  PRESSURE 101325\n",
      "  TEMPERATURE FILE temp_bottom.dat\n",
      "/\n",
      "\n",
      "#=========================== condition couplers ===============================\n",
      "# initial condition\n",
      "INITIAL_CONDITION initial\n",
      "  FLOW_CONDITION initial\n",
      "  REGION all\n",
      "END\n",
      "\n",
      "# Top boundary condition\n",
      "BOUNDARY_CONDITION top\n",
      "  FLOW_CONDITION flow_top\n",
      "  REGION top\n",
      "END\n",
      "\n",
      "# Bottom boundary condition\n",
      "BOUNDARY_CONDITION bottom\n",
      "  FLOW_CONDITION flow_bottom\n",
      "  REGION bottom\n",
      "END\n",
      "\n",
      "#=========================== stratigraphy couplers ============================\n",
      "\n",
      "STRATA\n",
      "  REGION all\n",
      "  MATERIAL Alluvium\n",
      "END\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "END_SUBSURFACE\n"
     ]
    }
   ],
   "source": [
    "%%script bash -s \"$pflotran_in\"\n",
    "cat $1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='pflotran_spinup'></a>\n",
    "# Step 3: PFLOTRAN model spin-up\n",
    "Take in the ```pflotran.in``` and ```parameter.h5``` files and conduct the model spin-up by running ```pflotran.sh``` file. The ```pflotran.sh``` is a simple shell script executing ensemble simulation of PFLOTRAN by using MPI.\n",
    "\n",
    "**Run the code**\n",
    "- Run: ```prepare_pflotran_inpara.py```\n",
    "- Code input arguments (loaded from the configuration file):\n",
    "    - <span style=\"background-color:lightgreen\">pflotran_exe</span>: location of the executable PFLOTRAN\n",
    "    - <span style=\"background-color:lightgreen\">pflotran_in</span>: filename for ```pflotran.in```\n",
    "    - <span style=\"background-color:lightgreen\">pflotran_out_dir</span>: directory of PFLOTRAN output\n",
    "    - <span style=\"background-color:lightgreen\">nens</span>: number of ensemble\n",
    "    - <span style=\"background-color:lightgreen\">mpi_exe, ncore</span>: location of mpirun and number of cpu cores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 896,
   "metadata": {},
   "outputs": [],
   "source": [
    "pflotran_sh, pflotran_out_dir = files_cfg[\"pflotran_sh_file\"], dirs_cfg[\"pflotran_out_dir\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 897,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "          10\n",
      " here\n",
      " here\n",
      "          10\n",
      "          10\n",
      " here\n",
      "          10\n",
      "Finished running PFLOTRAN...\n"
     ]
    }
   ],
   "source": [
    "%%script bash -s \"$pflotran_sh\" \"$config_file\"\n",
    "$1 $2\n",
    "# %%script bash -s \"$pflotran_sh\" \"$pflotran_exe\" \"$pflotran_in\" \"$pflotran_in_dir\" \"$pflotran_out_dir\" \"$nens\" \"$mpi_exe\" \"$ncore_pf\"\n",
    "# $1 $2 $3 $4 $5 $6 $7 $8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****************\n",
    "**Once the model spinup finishes, modify the corresponding configuration entry**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 898,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs[\"time_cfg\"][\"is_spinup_done\"] = True\n",
    "configs.write(config_file, force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 899,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cd $1\n",
    "# ls *.h5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='dart_prepare'></a>\n",
    "# Step 4: DART files preparation\n",
    "In this section, the following procedures are performed:\n",
    "- generate the template for DART generic variable quantity files (i.e., ```DEFAULT_obs_kind_mod.F90``` and ```obs_def_pflotran_mod.f90```);\n",
    "- generate the DART input namelists;\n",
    "- generate DART prior NetCDF data ```prior_ensemble_[ENS].nc``` from PFLOTRAN's parameter and outputs;\n",
    "- generate DART posterior NetCDF files (*sharing the same variable names and dimensions as the prior NetCDF files but without the data values*);\n",
    "- convert the observation file to DART observation format;\n",
    "- check ```model_mod.F90``` based on current setting by using the ```check_model_mod``` provided by DART."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='dart_generic_prepare'></a>\n",
    "## Generate the templates for DART generic variable quantity files\n",
    "- Run: ```list2dartqty.py``` to sequentially generate\n",
    "    - a mapping between PFLOTRAN variales and DART generic quantities in ```obs_def_pflotran_mod.F90```\n",
    "    - the default DART generic quantity definition file ```DEFAULT_obs_kind_mod.F90```\n",
    "- Code input arguments:\n",
    "    - <span style=\"background-color:lightgreen\">obs_type</span>: filename for ```DEFAULT_obs_kind_mod.F90```\n",
    "    - <span style=\"background-color:lightgreen\">def_obs_kind</span>: filename for ```obs_def_pflotran_mod.F90```\n",
    "    - <span style=\"background-color:lightgreen\">pflotran_parastate_set</span>: a list of variables required to be assimilated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 900,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_dartqty, obs_type_file = files_cfg[\"to_dartqty_file\"], files_cfg[\"obs_type_file\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 901,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No new DART variable quantity is added...\n",
      "Finished generating the /Users/jian449/Codes/DART/manhattan/models/pflotran/obs_kind/DEFAULT_obs_kind_mod.f90...\n",
      "Finished generating the /Users/jian449/Codes/DART/manhattan/models/pflotran/applications/1dthermal_3var_120000s/obs_type/obs_def_pflotran_mod.f90...\n"
     ]
    }
   ],
   "source": [
    "%%script bash -s \"$to_dartqty\" \"$config_file\"\n",
    "python $1 $2 $3 $4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 902,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "! BEGIN DART PREPROCESS KIND LIST\n",
      "!TEMPERATURE,  QTY_PFLOTRAN_TEMPERATURE, COMMON_CODE\n",
      "!FLOW_FLUX,  QTY_PFLOTRAN_FLOW_FLUX, COMMON_CODE\n",
      "!POROSITY,  QTY_PFLOTRAN_POROSITY, COMMON_CODE\n",
      "!THERMAL_CONDUCTIVITY,  QTY_PFLOTRAN_THERMAL_CONDUCTIVITY, COMMON_CODE\n",
      "! END DART PREPROCESS KIND LIST\n"
     ]
    }
   ],
   "source": [
    "%%script bash -s \"$obs_type_file\"\n",
    "cat $1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate  DART input namelists in ```input.nml```\n",
    "\n",
    "The ```input.nml``` file is generated based on a template ```input.nml.template``` by modifying the following namelist entries:\n",
    "\n",
    "```input.nml.template``` $\\rightarrow$ ```input.nml```\n",
    "\n",
    "|filter_nml|obs_kind_nml|preprocess_nml|model_nml|convertnc_nml|\n",
    "|:--:|:--:|:--:|:--:|:--:|\n",
    "| input_state_file_list, output_state_file_list, ens_size, async, adv_ens_command, obs_sequence_in_name | assimilate_these_obs_types | input_files, input_obs_kind_mod_file | time_step_days, time_step_seconds, nvar, var_names, template_file, var_qtynames | netcdf_file, out_file |\n",
    "\n",
    "**Namelists from DART**\n",
    "- [filter_nml](https://www.image.ucar.edu/DAReS/DART/Manhattan/assimilation_code/modules/assimilation/filter_mod.html): namelist of the main module for driving ensemble filter assimilations\n",
    "- [obs_kind_nml](https://www.image.ucar.edu/DAReS/DART/Manhattan/assimilation_code/modules/observations/obs_kind_mod.html#Namelist): namelist for controling what observation types are to be assimilated\n",
    "- [preprocess_nml](https://www.image.ucar.edu/DAReS/Codes/DART/manhattan/assimilation_code/programs/preprocess/preprocess): namelist of the DART-supplied preprocessor program which creates observation kind and observation definition modules from a set of other specially formatted Fortran 90 files\n",
    "\n",
    "**Self-defined namelists**\n",
    "- model_nml: a self-defined namelist for providing the basic information in the model\n",
    "    - time_step_days, time_step_seconds: the assimilation time window\n",
    "    - template_file: the template prior NetCDF file for ```model_mod.F90``` to digest the spatial information of the model\n",
    "    - var_names: the original variable names\n",
    "    - var_qtynames: the corresponding DART variable quantities\n",
    "    - nvar: the number of variables\n",
    "- convertnc_nml: a self-defined namelist for providing the NetCDF observation file name and the DART observation file name used in ```convert_nc.f90```\n",
    "    - netcdf_file: the location of the NetCDF file containing the observation data\n",
    "    - out_file: the location of the DART observation file\n",
    "\n",
    "**Note that**\n",
    "- There are more namelists or other items in the above namelist in input.nml.template. Users can edit the below python dictionary ```inputnml``` to include their modifications.\n",
    "- Users can also include more namelists provided by DART by modifying ```inputnml```."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***************\n",
    "**Assemble all the namelists in input.nml**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 903,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for different namelists in input.nml\n",
    "filter_nml = {\"input_state_file_list\":files_cfg[\"dart_input_list_file\"],\n",
    "              \"output_state_file_list\":files_cfg[\"dart_output_list_file\"],\n",
    "              \"ens_size\":da_cfg[\"nens\"],\n",
    "              \"num_output_state_members\":da_cfg[\"nens\"],\n",
    "              \"obs_sequence_in_name\":files_cfg[\"obs_dart_file\"]}\n",
    "#               \"obs_window_days\":obs_window_days,\n",
    "#               \"obs_window_seconds\":obs_window_seconds}\n",
    "assim_tools_nml = {\"filter_kind\": 2}\n",
    "obs_kind_nml = {\"assimilate_these_obs_types\":obs_set}\n",
    "model_nml = {\"time_step_days\":da_cfg[\"assim_window_days\"],\n",
    "             \"time_step_seconds\":da_cfg[\"assim_window_seconds\"],\n",
    "             \"nvar\":len(obs_set)+len(para_set),\n",
    "             \"var_names\":obs_set+para_set,\n",
    "             \"template_file\":files_cfg[\"dart_prior_template_file\"],\n",
    "             \"var_qtynames\":['QTY_PFLOTRAN_'+v for v in obs_set]+['QTY_PFLOTRAN_'+v for v in para_set]}\n",
    "preprocess_nml = {\"input_files\":files_cfg[\"obs_type_file\"],\n",
    "                  \"input_obs_kind_mod_file\":files_cfg[\"def_obs_kind_file\"]}\n",
    "convertnc_nml = {\"netcdf_file\": files_cfg[\"obs_nc_file\"],\n",
    "                 \"out_file\": files_cfg[\"obs_dart_file\"],\n",
    "                 \"obs_start_day\": da_cfg[\"assim_start_days\"],\n",
    "                 \"obs_start_second\": da_cfg[\"assim_start_seconds\"],\n",
    "                 \"obs_end_day\": da_cfg[\"assim_end_days\"],\n",
    "                 \"obs_end_second\":da_cfg[\"assim_end_seconds\"]}\n",
    "modelmodcheck_nml = {\"input_state_files\": files_cfg[\"dart_prior_template_file\"]}\n",
    "inputnml = {\"filter_nml\":filter_nml,\n",
    "            \"obs_kind_nml\":obs_kind_nml,\n",
    "            \"model_nml\":model_nml,\n",
    "            \"preprocess_nml\":preprocess_nml,\n",
    "            \"convert_nc_nml\":convertnc_nml,\n",
    "            \"model_mod_check_nml\":modelmodcheck_nml}\n",
    "\n",
    "\n",
    "configs[\"inputnml_cfg\"] = inputnml\n",
    "\n",
    "# Save the configurations\n",
    "configs.write(config_file, force=True)\n",
    "# with open(config_pickle, 'wb') as f:\n",
    "#     pickle.dump(configs, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***************\n",
    "**Run the code**\n",
    "- Run: ```prepare_inputnml.py```\n",
    "- Code input arguments:\n",
    "    - <span style=\"background-color:lightgreen\">input_nml</span>: the ```input.nml``` namelist file\n",
    "    - <span style=\"background-color:lightgreen\">input_nml_dict</span>: the ```inputnml.p``` pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 904,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_inputnml = files_cfg[\"prep_inputnml_file\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 905,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished generating the input namelist file...\n"
     ]
    }
   ],
   "source": [
    "%%script bash -s  \"$prep_inputnml\" \"$config_file\"\n",
    "python $1 $2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert the model output to DART prior NetCDF and  generate the preliminary DART posterior NetCDF file\n",
    "- The structure of ```prior_ensemble_[ENS].nc``` and ```posterior_ensemble_[ENS].nc``` files (```[ENS]``` refers to the ensemble number):\n",
    "\n",
    "| NetCDF dimensions |                      NetCDF variables                      |\n",
    "|:-----------------:|:----------------------------------------------------------:|\n",
    "| time: 1           | time: shape(time)                                          |\n",
    "| x_location: nx    | x_location: shape(x_location)                              |\n",
    "| y_location: ny    | y_location: shape(y_location)                              |\n",
    "| z_location: nz    | z_location: shape(z_location)                              |\n",
    "| member: 1         | member: shape(member)                                      |\n",
    "|                   | physical variable: shape(x_location,y_location,z_location) |\n",
    "\n",
    "**Note that** \n",
    "- required by DART, each ```prior_R[ENS].nc``` file only includes the state/parameter values of one ensemble member at one given time. \n",
    "- For the time, we set the initial time as 0, with time units converted *day* (requied by DART's ```read_model_time``` subroutine). \n",
    "- Also, it is different from the definition for the [observation NetCDF](#observationconvertion), because ```prior_R[ENS].nc``` aims for the structured cartesian grids while the observation NetCDF aims for a general case.\n",
    "\n",
    "**Run the code**\n",
    "- Run: ```prepare_prior_nc.py``` to generate \n",
    "    - the DART prior input file ```prior_ensemble_[ENS].nc```\n",
    "    - the DART posterior output file ```prior_ensemble_[ENS].nc``` (*sharing the same variable names and dimensions as the prior files but without the variable values*)\n",
    "    - the prior template file (copied from ```prior_ensemble_1.nc```) used by ```input.nml```\n",
    "    - the dart_input_list and dart_output_list used by DART\n",
    "- Code input arguments:\n",
    "    - <span style=\"background-color:lightgreen\">pflotran_out</span>: filename ```R[ENS].h5``` from PFLOTRAN model output\n",
    "    - <span style=\"background-color:lightgreen\">pflotran_para</span>: pflotran parameter HDF file ```parameter.h5```\n",
    "    - <span style=\"background-color:lightgreen\">dart_prior_nc</span>: filename ```prior_R[ENS].nc``` for the prior input file for DART\n",
    "    - <span style=\"background-color:lightgreen\">dart_input_list</span>: filename for recording the list of dart_prior_nc\n",
    "    - <span style=\"background-color:lightgreen\">nens</span>: number of ensemble\n",
    "    - <span style=\"background-color:lightgreen\">spinup</span>: whether it is spinup (if yes, the time is set to zero; otherwise, the time is read from ```R[ENS].h5```)\n",
    "    - <span style=\"background-color:lightgreen\">pflotran_parastate_set</span>: a list of variables to be assimilated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 906,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_prior_nc, dart_prior_template = files_cfg[\"prep_prior_nc_file\"], files_cfg[\"dart_prior_template_file\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 907,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting state/parameter into NetCDF file for ensemble 1...\n",
      "Converting state/parameter into NetCDF file for ensemble 2...\n",
      "Converting state/parameter into NetCDF file for ensemble 3...\n",
      "Converting state/parameter into NetCDF file for ensemble 4...\n",
      "Converting state/parameter into NetCDF file for ensemble 5...\n",
      "Converting state/parameter into NetCDF file for ensemble 6...\n",
      "Converting state/parameter into NetCDF file for ensemble 7...\n",
      "Converting state/parameter into NetCDF file for ensemble 8...\n",
      "Converting state/parameter into NetCDF file for ensemble 9...\n",
      "Converting state/parameter into NetCDF file for ensemble 10...\n",
      "Converting state/parameter into NetCDF file for ensemble 11...\n",
      "Converting state/parameter into NetCDF file for ensemble 12...\n",
      "Converting state/parameter into NetCDF file for ensemble 13...\n",
      "Converting state/parameter into NetCDF file for ensemble 14...\n",
      "Converting state/parameter into NetCDF file for ensemble 15...\n",
      "Converting state/parameter into NetCDF file for ensemble 16...\n",
      "Converting state/parameter into NetCDF file for ensemble 17...\n",
      "Converting state/parameter into NetCDF file for ensemble 18...\n",
      "Converting state/parameter into NetCDF file for ensemble 19...\n",
      "Converting state/parameter into NetCDF file for ensemble 20...\n",
      "Converting state/parameter into NetCDF file for ensemble 21...\n",
      "Converting state/parameter into NetCDF file for ensemble 22...\n",
      "Converting state/parameter into NetCDF file for ensemble 23...\n",
      "Converting state/parameter into NetCDF file for ensemble 24...\n",
      "Converting state/parameter into NetCDF file for ensemble 25...\n",
      "Converting state/parameter into NetCDF file for ensemble 26...\n",
      "Converting state/parameter into NetCDF file for ensemble 27...\n",
      "Converting state/parameter into NetCDF file for ensemble 28...\n",
      "Converting state/parameter into NetCDF file for ensemble 29...\n",
      "Converting state/parameter into NetCDF file for ensemble 30...\n",
      "Converting state/parameter into NetCDF file for ensemble 31...\n",
      "Converting state/parameter into NetCDF file for ensemble 32...\n",
      "Converting state/parameter into NetCDF file for ensemble 33...\n",
      "Converting state/parameter into NetCDF file for ensemble 34...\n",
      "Converting state/parameter into NetCDF file for ensemble 35...\n",
      "Converting state/parameter into NetCDF file for ensemble 36...\n",
      "Converting state/parameter into NetCDF file for ensemble 37...\n",
      "Converting state/parameter into NetCDF file for ensemble 38...\n",
      "Converting state/parameter into NetCDF file for ensemble 39...\n",
      "Converting state/parameter into NetCDF file for ensemble 40...\n"
     ]
    }
   ],
   "source": [
    "%%script bash -s \"$prep_prior_nc\" \"$config_file\"\n",
    "python $1 $2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 908,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "netcdf prior_ensemble_template {\n",
      "dimensions:\n",
      "\tx_location = 1 ;\n",
      "\ty_location = 1 ;\n",
      "\tz_location = 64 ;\n",
      "\ttime = 1 ;\n",
      "\tmember = 1 ;\n",
      "variables:\n",
      "\tdouble time(time) ;\n",
      "\t\ttime:units = \"day\" ;\n",
      "\t\ttime:calendar = \"none\" ;\n",
      "\t\ttime:type = \"dimension_value\" ;\n",
      "\tint64 member(member) ;\n",
      "\t\tmember:type = \"dimension_value\" ;\n",
      "\tdouble x_location(x_location) ;\n",
      "\t\tx_location:units = \"m\" ;\n",
      "\t\tx_location:type = \"dimension_value\" ;\n",
      "\tdouble y_location(y_location) ;\n",
      "\t\ty_location:units = \"m\" ;\n",
      "\t\ty_location:type = \"dimension_value\" ;\n",
      "\tdouble z_location(z_location) ;\n",
      "\t\tz_location:units = \"m\" ;\n",
      "\t\tz_location:type = \"dimension_value\" ;\n",
      "\tdouble TEMPERATURE(z_location, y_location, x_location) ;\n",
      "\t\tTEMPERATURE:type = \"observation_value\" ;\n",
      "\t\tTEMPERATURE:unit = \"[C]\" ;\n",
      "\tdouble FLOW_FLUX(z_location, y_location, x_location) ;\n",
      "\t\tFLOW_FLUX:type = \"observation_value\" ;\n",
      "\t\tFLOW_FLUX:unit = \"\" ;\n",
      "\tdouble POROSITY(z_location, y_location, x_location) ;\n",
      "\t\tPOROSITY:type = \"observation_value\" ;\n",
      "\t\tPOROSITY:unit = \"\" ;\n",
      "\tdouble THERMAL_CONDUCTIVITY(z_location, y_location, x_location) ;\n",
      "\t\tTHERMAL_CONDUCTIVITY:type = \"observation_value\" ;\n",
      "\t\tTHERMAL_CONDUCTIVITY:unit = \"\" ;\n",
      "\n",
      "// global attributes:\n",
      "\t\t:model_time = 0. ;\n",
      "\t\t:time_unit = \"day\" ;\n",
      "\t\t:assimilation_window = 0.0208333333333333 ;\n",
      "\t\t:description = \"PFLOTRAN output/DART prior data\" ;\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "%%script bash -s \"$dart_prior_template\"\n",
    "ncdump -h $1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='observationconvertion'></a>\n",
    "## Prepare the observation conversion to DART observation format\n",
    "In this section, we prepare the process of converting the observation data to DART format. We first convert observation data in raw format into NetCDF format. Then, a fortran script is prepared for the conversion from the NetCDF to to DART format. The structure of NetCDF file for recording observation file.\n",
    "\n",
    "| NetCDF dimensions |           NetCDF variables          |\n",
    "|:-----------------:|:-----------------------------------:|\n",
    "| time: 1           | time: shape(time)                   |\n",
    "| location: nloc    | location: shape(location)           |\n",
    "|                   | physical variable: shape(time,nloc) |\n",
    "\n",
    "**Note that** \n",
    "- if the time calendar follows *gregorian*, the time unit should be entered as ```seconds since YYYY-MM-DD HH:MM:SS```. Otherwise, put the time calender as *None* and time unit as ```second``` (make sure convert your measurement times to seconds)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***************\n",
    "**Convert the raw csv temperature observations to NetCDF file**\n",
    "- Run: ```csv2nc.py```\n",
    "- Code input arguments:\n",
    "    - <span style=\"background-color:lightgreen\">obs_original</span>: filename for the original observed temperature file\n",
    "    - <span style=\"background-color:lightgreen\">obs_nc</span>: filename for the observation NetCDF file\n",
    "    - <span style=\"background-color:lightgreen\">assim_start_str</span>: the reference time to set zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 909,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_to_nc, obs_nc_original = files_cfg[\"csv_to_nc_file\"], files_cfg[\"obs_nc_original_file\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 910,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.5        -0.49652778 -0.49305556 ... 29.49236111 29.49583333\n",
      " 29.49930556]\n",
      "Finished converting raw observation in NetCDF format...\n",
      "/Users/jian449/Codes/DART/manhattan/models/pflotran/utils/csv2nc.py:71: UserWarning: The following file already exists: /Users/jian449/Codes/DART/manhattan/models/pflotran/applications/1dthermal_3var_120000s/pflotran_input/obs_pflotran_original.nc\n",
      "  warnings.warn(\"The following file already exists: %s\" % obs_nc)\n"
     ]
    }
   ],
   "source": [
    "%%script bash -s \"$csv_to_nc\" \"$config_file\"\n",
    "python $1 $2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 911,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "netcdf obs_pflotran_original {\n",
      "dimensions:\n",
      "\ttime = 8641 ;\n",
      "\tlocation = 5 ;\n",
      "variables:\n",
      "\tdouble time(time) ;\n",
      "\t\ttime:calendar = \"None\" ;\n",
      "\t\ttime:units = \"days\" ;\n",
      "\t\ttime:type = \"dimension_value\" ;\n",
      "\tdouble x_location(location) ;\n",
      "\t\tx_location:units = \"m\" ;\n",
      "\t\tx_location:type = \"dimension_value\" ;\n",
      "\tdouble y_location(location) ;\n",
      "\t\ty_location:units = \"m\" ;\n",
      "\t\ty_location:type = \"dimension_value\" ;\n",
      "\tdouble z_location(location) ;\n",
      "\t\tz_location:units = \"m\" ;\n",
      "\t\tz_location:type = \"dimension_value\" ;\n",
      "\tdouble TEMPERATURE(location, time) ;\n",
      "\t\tTEMPERATURE:_FillValue = -99999. ;\n",
      "\t\tTEMPERATURE:unit = \"C\" ;\n",
      "\t\tTEMPERATURE:type = \"observation_value\" ;\n",
      "\tdouble TEMPERATURE_ERR(location, time) ;\n",
      "\t\tTEMPERATURE_ERR:_FillValue = -99999. ;\n",
      "\t\tTEMPERATURE_ERR:unit = \"C\" ;\n",
      "\t\tTEMPERATURE_ERR:type = \"observation_err_value\" ;\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "%%script bash -s \"$obs_nc_original\"\n",
    "ncdump -h $1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***************\n",
    "**Clip the NetCDF file based on the defined spatial and temporal domains**\n",
    "\n",
    "The NetCDF file generated in the previous step is further processed by selecting data observed in the required spatial and temporal domains\n",
    "- Run: ```clip_obs_nc.py```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 912,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_obs_nc, obs_nc = files_cfg[\"clip_obs_nc_file\"], files_cfg[\"obs_nc_file\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 913,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jian449/Codes/DART/manhattan/models/pflotran/utils/clip_obs_nc.py:53: UserWarning: The following file exists and thus is deleted: /Users/jian449/Codes/DART/manhattan/models/pflotran/applications/1dthermal_3var_120000s/pflotran_input/obs_pflotran_clipped.nc\n",
      "  warnings.warn(\"The following file exists and thus is deleted: %s\" % obs_nc)\n"
     ]
    }
   ],
   "source": [
    "%%script bash -s \"$clip_obs_nc\" \"$config_file\"\n",
    "python $1 $2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 914,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "netcdf obs_pflotran_clipped {\n",
      "dimensions:\n",
      "\ttime = 600 ;\n",
      "\tlocation = 3 ;\n",
      "variables:\n",
      "\tdouble time(time) ;\n",
      "\t\ttime:calendar = \"None\" ;\n",
      "\t\ttime:units = \"days\" ;\n",
      "\t\ttime:type = \"dimension_value\" ;\n",
      "\tdouble x_location(location) ;\n",
      "\t\tx_location:units = \"m\" ;\n",
      "\t\tx_location:type = \"dimension_value\" ;\n",
      "\tdouble y_location(location) ;\n",
      "\t\ty_location:units = \"m\" ;\n",
      "\t\ty_location:type = \"dimension_value\" ;\n",
      "\tdouble z_location(location) ;\n",
      "\t\tz_location:units = \"m\" ;\n",
      "\t\tz_location:type = \"dimension_value\" ;\n",
      "\tdouble TEMPERATURE(location, time) ;\n",
      "\t\tTEMPERATURE:_FillValue = -99999. ;\n",
      "\t\tTEMPERATURE:unit = \"C\" ;\n",
      "\t\tTEMPERATURE:type = \"observation_value\" ;\n",
      "\tdouble TEMPERATURE_ERR(location, time) ;\n",
      "\t\tTEMPERATURE_ERR:_FillValue = -99999. ;\n",
      "\t\tTEMPERATURE_ERR:unit = \"C\" ;\n",
      "\t\tTEMPERATURE_ERR:type = \"observation_err_value\" ;\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "%%script bash -s \"$obs_nc\"\n",
    "ncdump -h $1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***************\n",
    "**Prepare the ```convert_nc.f90``` based on the list of observation variables**\n",
    "- Run: ```prepare_convert_nc.py```\n",
    "- Code input arguments:\n",
    "    - <span style=\"background-color:lightgreen\">obs_nc</span>: filename for the observation NetCDF file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 915,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_convert_nc, convert_nc_file = files_cfg[\"prep_convert_nc_file\"], files_cfg[\"convert_nc_file\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 916,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script bash -s \"$prep_convert_nc\" \"$config_file\"\n",
    "python $1 $2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 917,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "! DART software - Copyright UCAR. This open source software is provided\n",
      "! by UCAR, \"as is\", without charge, subject to all terms of use at\n",
      "! http://www.image.ucar.edu/DAReS/DART/DART_download\n",
      "!\n",
      "! Revised from convert_madis_profiler.f90 written by Nancy Colin\n",
      "! $Id: convert_nc.f90 2019-09-09 15:48:00Z peishi.jiang@pnnl.gov $\n",
      "\n",
      "program convert_nc\n",
      "\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n"
     ]
    }
   ],
   "source": [
    "%%script bash -s \"$convert_nc_file\"\n",
    "head $1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='dart_executables'></a>\n",
    "# Step 5: Generate all the executable files\n",
    "Now, we compile all the executables from ```mkmf_*```. The following executables are generated here:\n",
    "- ```preprocess```: for preprocessing the [prepared DART generic variable quantity files prepared](#dart_generic_prepare)\n",
    "- ```convert_nc```: for [converting the observations from NetCDF to DART format](#observationconvertion)\n",
    "- ```model_mod_check```: for checking ```model_mod.F90``` interface file\n",
    "- ```filter```: for conducting the [DART data assimilation](https://www.image.ucar.edu/DAReS/DART/Manhattan/assimilation_code/programs/filter/filter.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the executables\n",
    "- Run: ```quickbuild.csh```\n",
    "- Code input arguments:\n",
    "    - <span style=\"background-color:lightgreen\">app_work_dir</span>: location of the application work folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 918,
   "metadata": {},
   "outputs": [],
   "source": [
    "dart_work_dir, app_work_dir = dirs_cfg[\"dart_work_dir\"], dirs_cfg[\"app_work_dir\"]\n",
    "quickbuild = files_cfg[\"quickbuild_csh\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 919,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cd $1\n",
    "# csh $2 $3 -mpi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert the observation file in NetCDF to DART format\n",
    "- Run: ```convert_nc```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 920,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_nc, obs_dart = files_cfg[\"convert_nc_exe\"], files_cfg[\"obs_dart_file\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 921,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " --------------------------------------\n",
      " Starting ... at YYYY MM DD HH MM SS = \n",
      "                 2019 10 14 19 59  9\n",
      " Program convert_nc\n",
      " --------------------------------------\n",
      "\n",
      "  set_nml_output No echo of NML values\n",
      "  write_obs_seq  opening formatted observation sequence file \"/Users/jian449/Codes/DART/manhattan/models/pflotran/applications/1dthermal_3var_120000s/dart_inout/obs_seq_pflotran.out\"\n",
      "\n",
      " --------------------------------------------------------\n",
      " -------------- ASSIMILATE_THESE_OBS_TYPES --------------\n",
      "    TEMPERATURE\n",
      " --------------------------------------------------------\n",
      " -------------- EVALUATE_THESE_OBS_TYPES   --------------\n",
      "    none\n",
      " --------------------------------------------------------\n",
      " ---------- USE_PRECOMPUTED_FO_OBS_TYPES   --------------\n",
      "    none\n",
      " --------------------------------------------------------\n",
      "\n",
      "  write_obs_seq  closed observation sequence file \"/Users/jian449/Codes/DART/manhattan/models/pflotran/applications/1dthermal_3var_120000s/dart_inout/obs_seq_pflotran.out\"\n",
      "\n",
      " --------------------------------------\n",
      " Finished ... at YYYY MM DD HH MM SS = \n",
      "                 2019 10 14 19 59  9\n",
      " --------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%script bash -s \"$app_work_dir\" \"$convert_nc\"\n",
    "cd $1\n",
    "$2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 922,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obs_sequence\n",
      "obs_kind_definitions\n",
      "           1\n",
      "           1 TEMPERATURE                                                     \n",
      "  num_copies:            1  num_qc:            1\n",
      "  num_obs:           18  max_num_obs:           18\n",
      "observations                                                    \n",
      "Data QC                                                         \n",
      "  first:            1  last:           18\n",
      " OBS            1\n",
      "   5.5177550000000002     \n",
      "   1.0000000000000000     \n",
      "          -1           2          -1\n",
      "obdef\n",
      "loc3Dxyz\n",
      "     0.000000000000000         0.000000000000000       -0.5000000000000000E-01\n",
      "kind\n",
      "           1\n",
      "   240          0\n",
      "   3.0445620240025007E-003\n",
      " OBS            2\n",
      "   5.3597289999999997     \n",
      "   1.0000000000000000     \n",
      "           1           3          -1\n",
      "obdef\n",
      "loc3Dxyz\n",
      "     0.000000000000000         0.000000000000000       -0.1500000000000000    \n",
      "kind\n",
      "           1\n",
      "   240          0\n",
      "   2.8726694953440999E-003\n",
      " OBS            3\n",
      "   5.2627160000000002     \n",
      "   1.0000000000000000     \n",
      "           2           4          -1\n",
      "obdef\n",
      "loc3Dxyz\n",
      "     0.000000000000000         0.000000000000000       -0.2500000000000000    \n",
      "kind\n",
      "           1\n",
      "   240          0\n",
      "   2.7696179696656007E-003\n",
      " OBS            4\n",
      "   5.5268319999999997     \n",
      "   1.0000000000000000     \n",
      "           3           5          -1\n",
      "obdef\n",
      "loc3Dxyz\n",
      "     0.000000000000000         0.000000000000000       -0.5000000000000000E-01\n",
      "kind\n",
      "           1\n",
      "   540          0\n",
      "   3.0545871956223995E-003\n",
      " OBS            5\n",
      "   5.3664870000000002     \n",
      "   1.0000000000000000     \n",
      "           4           6          -1\n",
      "obdef\n",
      "loc3Dxyz\n",
      "     0.000000000000000         0.000000000000000       -0.1500000000000000    \n",
      "kind\n",
      "           1\n",
      "   540          0\n",
      "   2.8799182721169002E-003\n",
      " OBS            6\n",
      "   5.2664080000000002     \n",
      "   1.0000000000000000     \n",
      "           5           7          -1\n",
      "obdef\n",
      "loc3Dxyz\n",
      "     0.000000000000000         0.000000000000000       -0.2500000000000000    \n",
      "kind\n",
      "           1\n",
      "   540          0\n",
      "   2.7735053222464000E-003\n",
      " OBS            7\n",
      "   5.5361410000000006     \n",
      "   1.0000000000000000     \n",
      "           6           8          -1\n",
      "obdef\n",
      "loc3Dxyz\n",
      "     0.000000000000000         0.000000000000000       -0.5000000000000000E-01\n",
      "kind\n",
      "           1\n",
      "   840          0\n",
      "   3.0648857171881008E-003\n",
      " OBS            8\n",
      "   5.3732350000000002     \n",
      "   1.0000000000000000     \n",
      "           7           9          -1\n",
      "obdef\n",
      "loc3Dxyz\n",
      "     0.000000000000000         0.000000000000000       -0.1500000000000000    \n",
      "kind\n",
      "           1\n",
      "   840          0\n",
      "   2.8871654365225006E-003\n",
      " OBS            9\n",
      "   5.2702019999999994     \n",
      "   1.0000000000000000     \n"
     ]
    }
   ],
   "source": [
    "%%script bash -s \"$obs_dart\"\n",
    "head -n100 $1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check ```model_mod.F90``` interface file\n",
    "- Run: ```model_mod_check```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 923,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mod_check = files_cfg[\"model_mod_check_exe\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 924,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " --------------------------------------\n",
      " Starting ... at YYYY MM DD HH MM SS = \n",
      "                 2019 10 14 19 59  9\n",
      " Program model_mod_check\n",
      " --------------------------------------\n",
      "\n",
      "  set_nml_output No echo of NML values\n",
      "  initialize_mpi_utilities: Running single process\n",
      "\n",
      "\n",
      "***************** RUNNING    TEST 0    ***********************\n",
      " -- Reading the model_mod namelist and implicitly running static_init_model\n",
      "**************************************************************\n",
      "\n",
      " --------------------------------------------------------\n",
      " -------------- ASSIMILATE_THESE_OBS_TYPES --------------\n",
      "    TEMPERATURE\n",
      " --------------------------------------------------------\n",
      " -------------- EVALUATE_THESE_OBS_TYPES   --------------\n",
      "    none\n",
      " --------------------------------------------------------\n",
      " ---------- USE_PRECOMPUTED_FO_OBS_TYPES   --------------\n",
      "    none\n",
      " --------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "***************** FINISHED   TEST 0    ***********************\n",
      "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n",
      "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n",
      "\n",
      "\n",
      "***************** RUNNING    TEST 1    ***********************\n",
      " -- Verifying composition of the state and calling get_model_size()\n",
      "**************************************************************\n",
      "--------------------------------------------------------------\n",
      "To suppress the detailed list of the variables that comprise the DART state\n",
      " -- set \"verbose = .FALSE.\" in the model_mod_check_nml namelist.\n",
      "--------------------------------------------------------------\n",
      "  \n",
      " Reporting on domain #            1\n",
      " Created by method \"file\"\n",
      " Origin file \"/Users/jian449/Codes/DART/manhattan/models/pflotran/applications/1dthermal_3var_120000s/dart_inout/prior_ensemble_template.nc\"\n",
      " Number of dimensions  :  3\n",
      " unlimdimid            : -1\n",
      "     1: dim_id = 1, length =        1, name = \"x_location\"\n",
      "     2: dim_id = 2, length =        1, name = \"y_location\"\n",
      "     3: dim_id = 3, length =       64, name = \"z_location\"\n",
      "\n",
      " VARNAME     : TEMPERATURE\n",
      " var_size    :           64\n",
      " index_start :                     1\n",
      " index_end   :                    64\n",
      " kind_string : QTY_PFLOTRAN_TEMPERATURE                                        \n",
      " dart_kind   : 367\n",
      " clamping    :  F\n",
      " minvalue    :   -888888.00000000000     \n",
      " maxvalue    :   -888888.00000000000     \n",
      " update      :  T\n",
      " unlimdimid  :           -1\n",
      " numdims     : 3\n",
      "     1:             length =        1, name = \"x_location\"\n",
      "     2:             length =        1, name = \"y_location\"\n",
      "     3:             length =       64, name = \"z_location\"\n",
      " io_numdims  : 3\n",
      "     1: dim_id = 1, length =        1, name = \"x_location\"\n",
      "     2: dim_id = 2, length =        1, name = \"y_location\"\n",
      "     3: dim_id = 3, length =       64, name = \"z_location\"\n",
      " CF-Conventions that exist in : /Users/jian449/Codes/DART/manhattan/models/pflotran/applications/1dthermal_3var_120000s/dart_inout/prior_ensemble_template.nc\n",
      " units             : \n",
      " short_name        : \n",
      " long_name         : \n",
      " has_missing_value :  F\n",
      "\n",
      " VARNAME     : FLOW_FLUX\n",
      " var_size    :           64\n",
      " index_start :                    65\n",
      " index_end   :                   128\n",
      " kind_string : QTY_PFLOTRAN_FLOW_FLUX                                          \n",
      " dart_kind   : 372\n",
      " clamping    :  F\n",
      " minvalue    :   -888888.00000000000     \n",
      " maxvalue    :   -888888.00000000000     \n",
      " update      :  T\n",
      " unlimdimid  :           -1\n",
      " numdims     : 3\n",
      "     1:             length =        1, name = \"x_location\"\n",
      "     2:             length =        1, name = \"y_location\"\n",
      "     3:             length =       64, name = \"z_location\"\n",
      " io_numdims  : 3\n",
      "     1: dim_id = 1, length =        1, name = \"x_location\"\n",
      "     2: dim_id = 2, length =        1, name = \"y_location\"\n",
      "     3: dim_id = 3, length =       64, name = \"z_location\"\n",
      " CF-Conventions that exist in : /Users/jian449/Codes/DART/manhattan/models/pflotran/applications/1dthermal_3var_120000s/dart_inout/prior_ensemble_template.nc\n",
      " units             : \n",
      " short_name        : \n",
      " long_name         : \n",
      " has_missing_value :  F\n",
      "\n",
      " VARNAME     : POROSITY\n",
      " var_size    :           64\n",
      " index_start :                   129\n",
      " index_end   :                   192\n",
      " kind_string : QTY_PFLOTRAN_POROSITY                                           \n",
      " dart_kind   : 369\n",
      " clamping    :  F\n",
      " minvalue    :   -888888.00000000000     \n",
      " maxvalue    :   -888888.00000000000     \n",
      " update      :  T\n",
      " unlimdimid  :           -1\n",
      " numdims     : 3\n",
      "     1:             length =        1, name = \"x_location\"\n",
      "     2:             length =        1, name = \"y_location\"\n",
      "     3:             length =       64, name = \"z_location\"\n",
      " io_numdims  : 3\n",
      "     1: dim_id = 1, length =        1, name = \"x_location\"\n",
      "     2: dim_id = 2, length =        1, name = \"y_location\"\n",
      "     3: dim_id = 3, length =       64, name = \"z_location\"\n",
      " CF-Conventions that exist in : /Users/jian449/Codes/DART/manhattan/models/pflotran/applications/1dthermal_3var_120000s/dart_inout/prior_ensemble_template.nc\n",
      " units             : \n",
      " short_name        : \n",
      " long_name         : \n",
      " has_missing_value :  F\n",
      "\n",
      " VARNAME     : THERMAL_CONDUCTIVITY\n",
      " var_size    :           64\n",
      " index_start :                   193\n",
      " index_end   :                   256\n",
      " kind_string : QTY_PFLOTRAN_THERMAL_CONDUCTIVITY                               \n",
      " dart_kind   : 373\n",
      " clamping    :  F\n",
      " minvalue    :   -888888.00000000000     \n",
      " maxvalue    :   -888888.00000000000     \n",
      " update      :  T\n",
      " unlimdimid  :           -1\n",
      " numdims     : 3\n",
      "     1:             length =        1, name = \"x_location\"\n",
      "     2:             length =        1, name = \"y_location\"\n",
      "     3:             length =       64, name = \"z_location\"\n",
      " io_numdims  : 3\n",
      "     1: dim_id = 1, length =        1, name = \"x_location\"\n",
      "     2: dim_id = 2, length =        1, name = \"y_location\"\n",
      "     3: dim_id = 3, length =       64, name = \"z_location\"\n",
      " CF-Conventions that exist in : /Users/jian449/Codes/DART/manhattan/models/pflotran/applications/1dthermal_3var_120000s/dart_inout/prior_ensemble_template.nc\n",
      " units             : \n",
      " short_name        : \n",
      " long_name         : \n",
      " has_missing_value :  F\n",
      "\n",
      "--------------------------------------------------------------\n",
      " state vector has a length of 256\n",
      "--------------------------------------------------------------\n",
      "\n",
      "\n",
      "***************** FINISHED   TEST 1    ***********************\n",
      "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n",
      "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n",
      "\n",
      "\n",
      "***************** RUNNING    TEST 2    ***********************\n",
      " -- Read and write restart file\n",
      "**************************************************************\n",
      "--------------------------------------------------------------\n",
      " Reading File : /Users/jian449/Codes/DART/manhattan/models/pflotran/applications/1dthermal_3var_120000s/dart_inout/prior_ensemble_template.nc\n",
      "--------------------------------------------------------------\n",
      "read_model_time day=0, sec=899\n",
      "--------------------------------------------------------------\n",
      " Writing File : /Users/jian449/Codes/DART/manhattan/models/pflotran/applications/1dthermal_3var_120000s/dart_inout/mmc_output.nc\n",
      "--------------------------------------------------------------\n",
      "\n",
      "-------------------------------------------------------------\n",
      "printing model time: \n",
      " model_mod_check:model time day=0, sec=899\n",
      "-------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "***************** FINISHED   TEST 2    ***********************\n",
      "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n",
      "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n",
      "\n",
      "\n",
      "***************** RUNNING    TEST 3    ***********************\n",
      " -- Testing get_state_meta_data()\n",
      "**************************************************************\n",
      "--------------------------------------------------------------\n",
      " requesting meta data for state vector index 100\n",
      " --  set by namelist item \"x_ind\"\n",
      "--------------------------------------------------------------\n",
      "--------------------------------------------------------------\n",
      "index         100 is i,j,k    1    1   36 and is in domain  1\n",
      " -- is quantity  372, QTY_PFLOTRAN_FLOW_FLUX at location\n",
      " -- X/Y/Z:        0.0000000            0.0000000          -0.29000000\n",
      "--------------------------------------------------------------\n",
      "\n",
      "\n",
      "***************** FINISHED   TEST 3    ***********************\n",
      "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n",
      "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n",
      "\n",
      "\n",
      "***************** RUNNING    TEST 4    ***********************\n",
      " -- Testing model_interpolate with a single location\n",
      "**************************************************************\n",
      "--------------------------------------------------------------\n",
      "Interpolating QTY_PFLOTRAN_TEMPERATURE\n",
      " --  at \"loc_of_interest\" location\n",
      "--------------------------------------------------------------\n",
      "\n",
      "-------------------------------------------------------------\n",
      "interpolating at  X/Y/Z:        0.0000000            2.3000000          -0.36000000\n",
      "interpolating for \"QTY_PFLOTRAN_TEMPERATURE\"\n",
      "-------------------------------------------------------------\n",
      "\n",
      "member     1, SUCCESS with value    ::    5.4746018582027505\n",
      "\n",
      "--------------------------------------------------------------\n",
      "interpolation successful for all ensemble members.\n",
      "--------------------------------------------------------------\n",
      "\n",
      "\n",
      "***************** FINISHED   TEST 4    ***********************\n",
      "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n",
      "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n",
      "--------------------------------------------------------------\n",
      "model_mod_check Finished successfully\n",
      "--------------------------------------------------------------\n",
      "\n",
      " --------------------------------------\n",
      " Finished ... at YYYY MM DD HH MM SS = \n",
      "                 2019 10 14 19 59  9\n",
      " Program model_mod_check\n",
      " --------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%script bash -s \"$app_work_dir\" \"$model_mod_check\"\n",
    "cd $1\n",
    "$2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='run_dart_pflotran'></a>\n",
    "# Step 6: Run DART and PFLOTRAN\n",
    "In this section, run the shell script to couple DART and PFLOTRAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 925,
   "metadata": {},
   "outputs": [],
   "source": [
    "dart_work_dir = dirs_cfg[\"dart_work_dir\"]\n",
    "inputnml_file = files_cfg[\"input_nml_file\"]\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 926,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "onverting state/parameter into NetCDF file for ensemble 37...\n",
      "Converting state/parameter into NetCDF file for ensemble 38...\n",
      "Converting state/parameter into NetCDF file for ensemble 39...\n",
      "Converting state/parameter into NetCDF file for ensemble 40...\n",
      "\n",
      "\n",
      "------------------------------------------------------------\n",
      "Generate the DART data observations in the current assimilation window ...\n",
      "\n",
      "\n",
      " --------------------------------------\n",
      " Starting ... at YYYY MM DD HH MM SS = \n",
      "                 2019 10 14 20  5 10\n",
      " Program convert_nc\n",
      " --------------------------------------\n",
      "\n",
      "  set_nml_output No echo of NML values\n",
      "  write_obs_seq  opening formatted observation sequence file \"/Users/jian449/Codes/DART/manhattan/models/pflotran/applications/1dthermal_3var_120000s/dart_inout/obs_seq_pflotran.out\"\n",
      "\n",
      " --------------------------------------------------------\n",
      " -------------- ASSIMILATE_THESE_OBS_TYPES --------------\n",
      "    TEMPERATURE\n",
      " --------------------------------------------------------\n",
      " -------------- EVALUATE_THESE_OBS_TYPES   --------------\n",
      "    none\n",
      " --------------------------------------------------------\n",
      " ---------- USE_PRECOMPUTED_FO_OBS_TYPES   --------------\n",
      "    none\n",
      " --------------------------------------------------------\n",
      "\n",
      "  write_obs_seq  closed observation sequence file \"/Users/jian449/Codes/DART/manhattan/models/pflotran/applications/1dthermal_3var_120000s/dart_inout/obs_seq_pflotran.out\"\n",
      "\n",
      " --------------------------------------\n",
      " Finished ... at YYYY MM DD HH MM SS = \n",
      "                 2019 10 14 20  5 10\n",
      " --------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "------------------------------------------------------------\n",
      "Start the assimilation at the current model time 2.0208333333333304 [day] ...\n",
      "\n",
      "\n",
      " --------------------------------------\n",
      " Starting ... at YYYY MM DD HH MM SS = \n",
      "                 2019 10 14 20  5 10\n",
      " Program Filter\n",
      " --------------------------------------\n",
      "\n",
      "  set_nml_output No echo of NML values\n",
      " PE 0: initialize_mpi_utilities:  Running with            4  MPI processes.\n",
      "\n",
      " --------------------------------------------------------\n",
      " -------------- ASSIMILATE_THESE_OBS_TYPES --------------\n",
      "    TEMPERATURE\n",
      " --------------------------------------------------------\n",
      " -------------- EVALUATE_THESE_OBS_TYPES   --------------\n",
      "    none\n",
      " --------------------------------------------------------\n",
      " ---------- USE_PRECOMPUTED_FO_OBS_TYPES   --------------\n",
      "    none\n",
      " --------------------------------------------------------\n",
      "\n",
      " PE 0: quality_control_mod: Will reject obs with Data QC larger than    3\n",
      " PE 0: quality_control_mod: No observation outlier threshold rejection will be done\n",
      " PE 0: assim_tools_init: Selected filter type is Ensemble Kalman Filter (ENKF)\n",
      " PE 0: assim_tools_init: The cutoff namelist value is     1000000.000000\n",
      " PE 0: assim_tools_init: ... cutoff is the localization half-width parameter,\n",
      " PE 0: assim_tools_init: ... so the effective localization radius is     2000000.000000\n",
      " PE 0: assim_tools_init: Replicating a copy of the ensemble mean on every task\n",
      " PE 0: assim_tools_init: ... uses more memory per task but may run faster if doing vertical\n",
      " PE 0: assim_tools_init: ... coordinate conversion; controlled by namelist item \"distribute_mean\"\n",
      " PE 0: filter_main: running with an ensemble size of    40\n",
      " PE 0: parse_stages_to_write:  filter will write stage : output\n",
      " PE 0: filter_main: running with distributed state; model states stay distributed across all tasks for the entire run\n",
      "read_model_time day=2, sec=2699\n",
      "read_model_time day=2, sec=2699\n",
      "read_model_time day=2, sec=2699\n",
      "read_model_time day=2, sec=2699\n",
      " PE 0: Prior inflation: None\n",
      " PE 0: Posterior inflation: None\n",
      " PE 0: filter_main: Reading in initial condition/restart data for all ensemble members from file(s)\n",
      " PE 0:\n",
      " PE 0: filter: Main assimilation loop, starting iteration    0\n",
      " PE 0: move_ahead Next assimilation window starts    at:  day=       2 sec=  1800\n",
      " PE 0: move_ahead Next assimilation window ends      at:  day=       2 sec=  3599\n",
      " PE 0: filter: Model does not need to run; data already at required time\n",
      " PE 0: filter: Ready to assimilate up to      18 observations\n",
      " PE 0: comp_cov_factor: Standard Gaspari Cohn localization selected\n",
      " PE 0: filter_assim: Processed      18 total observations\n",
      " PE 0:\n",
      " PE 0: filter: Main assimilation loop, starting iteration    1\n",
      " PE 0: filter: No more obs to assimilate, exiting main loop\n",
      " PE 0: filter: End of main filter assimilation loop, starting cleanup\n",
      " PE 0: write_obs_seq  opening formatted observation sequence file \"obs_seq.final\"\n",
      " PE 0: write_obs_seq  closed observation sequence file \"obs_seq.final\"\n",
      "\n",
      " --------------------------------------\n",
      " Finished ... at YYYY MM DD HH MM SS = \n",
      "                 2019 10 14 20  5 10\n",
      " Program Filter\n",
      " --------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "------------------------------------------------------------\n",
      "Move the time forward ...\n",
      "\n",
      "\n",
      "\n",
      "------------------------------------------------------------\n",
      "Update PFLOTRAN input files ...\n",
      "\n",
      "\n",
      "\n",
      "------------------------------------------------------------\n",
      "Conduct the ensemble forward simulation for PFLOTRAN ...\n",
      "\n",
      " here\n",
      "          10\n",
      " here\n",
      "          10\n",
      " here\n",
      "          10\n",
      " here\n",
      "          10\n",
      "Finished running PFLOTRAN...\n",
      "\n",
      "\n",
      "------------------------------------------------------------\n",
      "Convert the PFLOTRAN HDF output to DART prior NetCDF data ...\n",
      "\n",
      "Converting state/parameter into NetCDF file for ensemble 1...\n",
      "Converting state/parameter into NetCDF file for ensemble 2...\n",
      "Converting state/parameter into NetCDF file for ensemble 3...\n",
      "Converting state/parameter into NetCDF file for ensemble 4...\n",
      "Converting state/parameter into NetCDF file for ensemble 5...\n",
      "Converting state/parameter into NetCDF file for ensemble 6...\n",
      "Converting state/parameter into NetCDF file for ensemble 7...\n",
      "Converting state/parameter into NetCDF file for ensemble 8...\n",
      "Converting state/parameter into NetCDF file for ensemble 9...\n",
      "Converting state/parameter into NetCDF file for ensemble 10...\n",
      "Converting state/parameter into NetCDF file for ensemble 11...\n",
      "Converting state/parameter into NetCDF file for ensemble 12...\n",
      "Converting state/parameter into NetCDF file for ensemble 13...\n",
      "Converting state/parameter into NetCDF file for ensemble 14...\n",
      "Converting state/parameter into NetCDF file for ensemble 15...\n",
      "Converting state/parameter into NetCDF file for ensemble 16...\n",
      "Converting state/parameter into NetCDF file for ensemble 17...\n",
      "Converting state/parameter into NetCDF file for ensemble 18...\n",
      "Converting state/parameter into NetCDF file for ensemble 19...\n",
      "Converting state/parameter into NetCDF file for ensemble 20...\n",
      "Converting state/parameter into NetCDF file for ensemble 21...\n",
      "Converting state/parameter into NetCDF file for ensemble 22...\n",
      "Converting state/parameter into NetCDF file for ensemble 23...\n",
      "Converting state/parameter into NetCDF file for ensemble 24...\n",
      "Converting state/parameter into NetCDF file for ensemble 25...\n",
      "Converting state/parameter into NetCDF file for ensemble 26...\n",
      "Converting state/parameter into NetCDF file for ensemble 27...\n",
      "Converting state/parameter into NetCDF file for ensemble 28...\n",
      "Converting state/parameter into NetCDF file for ensemble 29...\n",
      "Converting state/parameter into NetCDF file for ensemble 30...\n",
      "Converting state/parameter into NetCDF file for ensemble 31...\n",
      "Converting state/parameter into NetCDF file for ensemble 32...\n",
      "Converting state/parameter into NetCDF file for ensemble 33...\n",
      "Converting state/parameter into NetCDF file for ensemble 34...\n",
      "Converting state/parameter into NetCDF file for ensemble 35...\n",
      "Converting state/parameter into NetCDF file for ensemble 36...\n",
      "Converting state/parameter into NetCDF file for ensemble 37...\n",
      "Converting state/parameter into NetCDF file for ensemble 38...\n",
      "Converting state/parameter into NetCDF file for ensemble 39...\n",
      "Converting state/parameter into NetCDF file for ensemble 40...\n",
      "\n",
      "\n",
      "------------------------------------------------------------\n",
      "Generate the DART data observations in the current assimilation window ...\n",
      "\n",
      "\n",
      " --------------------------------------\n",
      " Starting ... at YYYY MM DD HH MM SS = \n",
      "                 2019 10 14 20  5 14\n",
      " Program convert_nc\n",
      " --------------------------------------\n",
      "\n",
      "  set_nml_output No echo of NML values\n",
      "  write_obs_seq  opening formatted observation sequence file \"/Users/jian449/Codes/DART/manhattan/models/pflotran/applications/1dthermal_3var_120000s/dart_inout/obs_seq_pflotran.out\"\n",
      "\n",
      " --------------------------------------------------------\n",
      " -------------- ASSIMILATE_THESE_OBS_TYPES --------------\n",
      "    TEMPERATURE\n",
      " --------------------------------------------------------\n",
      " -------------- EVALUATE_THESE_OBS_TYPES   --------------\n",
      "    none\n",
      " --------------------------------------------------------\n",
      " ---------- USE_PRECOMPUTED_FO_OBS_TYPES   --------------\n",
      "    none\n",
      " --------------------------------------------------------\n",
      "\n",
      "  write_obs_seq  closed observation sequence file \"/Users/jian449/Codes/DART/manhattan/models/pflotran/applications/1dthermal_3var_120000s/dart_inout/obs_seq_pflotran.out\"\n",
      "\n",
      " --------------------------------------\n",
      " Finished ... at YYYY MM DD HH MM SS = \n",
      "                 2019 10 14 20  5 14\n",
      " --------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "------------------------------------------------------------\n",
      "Start the assimilation at the current model time 2.041666666666664 [day] ...\n",
      "\n",
      "\n",
      " --------------------------------------\n",
      " Starting ... at YYYY MM DD HH MM SS = \n",
      "                 2019 10 14 20  5 14\n",
      " Program Filter\n",
      " --------------------------------------\n",
      "\n",
      "  set_nml_output No echo of NML values\n",
      " PE 0: initialize_mpi_utilities:  Running with            4  MPI processes.\n",
      "\n",
      " --------------------------------------------------------\n",
      " -------------- ASSIMILATE_THESE_OBS_TYPES --------------\n",
      "    TEMPERATURE\n",
      " --------------------------------------------------------\n",
      " -------------- EVALUATE_THESE_OBS_TYPES   --------------\n",
      "    none\n",
      " --------------------------------------------------------\n",
      " ---------- USE_PRECOMPUTED_FO_OBS_TYPES   --------------\n",
      "    none\n",
      " --------------------------------------------------------\n",
      "\n",
      " PE 0: quality_control_mod: Will reject obs with Data QC larger than    3\n",
      " PE 0: quality_control_mod: No observation outlier threshold rejection will be done\n",
      " PE 0: assim_tools_init: Selected filter type is Ensemble Kalman Filter (ENKF)\n",
      " PE 0: assim_tools_init: The cutoff namelist value is     1000000.000000\n",
      " PE 0: assim_tools_init: ... cutoff is the localization half-width parameter,\n",
      " PE 0: assim_tools_init: ... so the effective localization radius is     2000000.000000\n",
      " PE 0: assim_tools_init: Replicating a copy of the ensemble mean on every task\n",
      " PE 0: assim_tools_init: ... uses more memory per task but may run faster if doing vertical\n",
      " PE 0: assim_tools_init: ... coordinate conversion; controlled by namelist item \"distribute_mean\"\n",
      " PE 0: filter_main: running with an ensemble size of    40\n",
      " PE 0: parse_stages_to_write:  filter will write stage : output\n",
      " PE 0: filter_main: running with distributed state; model states stay distributed across all tasks for the entire run\n",
      "read_model_time day=2, sec=4499\n",
      "read_model_time day=2, sec=4499\n",
      "read_model_time day=2, sec=4499\n",
      "read_model_time day=2, sec=4499\n",
      " PE 0: Prior inflation: None\n",
      " PE 0: Posterior inflation: None\n",
      " PE 0: filter_main: Reading in initial condition/restart data for all ensemble members from file(s)\n",
      " PE 0:\n",
      " PE 0: filter: Main assimilation loop, starting iteration    0\n",
      " PE 0: move_ahead Next assimilation window starts    at:  day=       2 sec=  3600\n",
      " PE 0: move_ahead Next assimilation window ends      at:  day=       2 sec=  5399\n",
      " PE 0: filter: Model does not need to run; data already at required time\n",
      " PE 0: filter: Ready to assimilate up to      18 observations\n",
      " PE 0: comp_cov_factor: Standard Gaspari Cohn localization selected\n",
      " PE 0: filter_assim: Processed      18 total observations\n",
      " PE 0:\n",
      " PE 0: filter: Main assimilation loop, starting iteration    1\n",
      " PE 0: filter: No more obs to assimilate, exiting main loop\n",
      " PE 0: filter: End of main filter assimilation loop, starting cleanup\n",
      " PE 0: write_obs_seq  opening formatted observation sequence file \"obs_seq.final\"\n",
      " PE 0: write_obs_seq  closed observation sequence file \"obs_seq.final\"\n",
      "\n",
      " --------------------------------------\n",
      " Finished ... at YYYY MM DD HH MM SS = \n",
      "                 2019 10 14 20  5 14\n",
      " Program Filter\n",
      " --------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "------------------------------------------------------------\n",
      "Move the time forward ...\n",
      "\n",
      "\n",
      "\n",
      "------------------------------------------------------------\n",
      "Update PFLOTRAN input files ...\n",
      "\n",
      "\n",
      "\n",
      "------------------------------------------------------------\n",
      "Conduct the ensemble forward simulation for PFLOTRAN ...\n",
      "\n",
      " here\n",
      "          10\n",
      " here\n",
      "          10\n",
      " here\n",
      "          10\n",
      " here\n",
      "          10\n",
      "Finished running PFLOTRAN...\n",
      "\n",
      "\n",
      "------------------------------------------------------------\n",
      "Convert the PFLOTRAN HDF output to DART prior NetCDF data ...\n",
      "\n",
      "Converting state/parameter into NetCDF file for ensemble 1...\n",
      "Converting state/parameter into NetCDF file for ensemble 2...\n",
      "Converting state/parameter into NetCDF file for ensemble 3...\n",
      "Converting state/parameter into NetCDF file for ensemble 4...\n",
      "Converting state/parameter into NetCDF file for ensemble 5...\n",
      "Converting state/parameter into NetCDF file for ensemble 6...\n",
      "Converting state/parameter into NetCDF file for ensemble 7...\n",
      "Converting state/parameter into NetCDF file for ensemble 8...\n",
      "Converting state/parameter into NetCDF file for ensemble 9...\n",
      "Converting state/parameter into NetCDF file for ensemble 10...\n",
      "Converting state/parameter into NetCDF file for ensemble 11...\n",
      "Converting state/parameter into NetCDF file for ensemble 12...\n",
      "Converting state/parameter into NetCDF file for ensemble 13...\n",
      "Converting state/parameter into NetCDF file for ensemble 14...\n",
      "Converting state/parameter into NetCDF file for ensemble 15...\n",
      "Converting state/parameter into NetCDF file for ensemble 16...\n",
      "Converting state/parameter into NetCDF file for ensemble 17...\n",
      "Converting state/parameter into NetCDF file for ensemble 18...\n",
      "Converting state/parameter into NetCDF file for ensemble 19...\n",
      "Converting state/parameter into NetCDF file for ensemble 20...\n",
      "Converting state/parameter into NetCDF file for ensemble 21...\n",
      "Converting state/parameter into NetCDF file for ensemble 22...\n",
      "Converting state/parameter into NetCDF file for ensemble 23...\n",
      "Converting state/parameter into NetCDF file for ensemble 24...\n",
      "Converting state/parameter into NetCDF file for ensemble 25...\n",
      "Converting state/parameter into NetCDF file for ensemble 26...\n",
      "Converting state/parameter into NetCDF file for ensemble 27...\n",
      "Converting state/parameter into NetCDF file for ensemble 28...\n",
      "Converting state/parameter into NetCDF file for ensemble 29...\n",
      "Converting state/parameter into NetCDF file for ensemble 30...\n",
      "Converting state/parameter into NetCDF file for ensemble 31...\n",
      "Converting state/parameter into NetCDF file for ensemble 32...\n",
      "Converting state/parameter into NetCDF file for ensemble 33...\n",
      "Converting state/parameter into NetCDF file for ensemble 34...\n",
      "Converting state/parameter into NetCDF file for ensemble 35...\n",
      "Converting state/parameter into NetCDF file for ensemble 36...\n",
      "Converting state/parameter into NetCDF file for ensemble 37...\n",
      "Converting state/parameter into NetCDF file for ensemble 38...\n",
      "Converting state/parameter into NetCDF file for ensemble 39...\n",
      "Converting state/parameter into NetCDF file for ensemble 40...\n",
      "\n",
      "\n",
      "------------------------------------------------------------\n",
      "Generate the DART data observations in the current assimilation window ...\n",
      "\n",
      "\n",
      " --------------------------------------\n",
      " Starting ... at YYYY MM DD HH MM SS = \n",
      "                 2019 10 14 20  5 17\n",
      " Program convert_nc\n",
      " --------------------------------------\n",
      "\n",
      "  set_nml_output No echo of NML values\n",
      "  write_obs_seq  opening formatted observation sequence file \"/Users/jian449/Codes/DART/manhattan/models/pflotran/applications/1dthermal_3var_120000s/dart_inout/obs_seq_pflotran.out\"\n",
      "\n",
      " --------------------------------------------------------\n",
      " -------------- ASSIMILATE_THESE_OBS_TYPES --------------\n",
      "    TEMPERATURE\n",
      " --------------------------------------------------------\n",
      " -------------- EVALUATE_THESE_OBS_TYPES   --------------\n",
      "    none\n",
      " --------------------------------------------------------\n",
      " ---------- USE_PRECOMPUTED_FO_OBS_TYPES   --------------\n",
      "    none\n",
      " --------------------------------------------------------\n",
      "\n",
      "  write_obs_seq  closed observation sequence file \"/Users/jian449/Codes/DART/manhattan/models/pflotran/applications/1dthermal_3var_120000s/dart_inout/obs_seq_pflotran.out\"\n",
      "\n",
      " --------------------------------------\n",
      " Finished ... at YYYY MM DD HH MM SS = \n",
      "                 2019 10 14 20  5 17\n",
      " --------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "------------------------------------------------------------\n",
      "Start the assimilation at the current model time 2.0624999999999973 [day] ...\n",
      "\n",
      "\n",
      " --------------------------------------\n",
      " Starting ... at YYYY MM DD HH MM SS = \n",
      "                 2019 10 14 20  5 18\n",
      " Program Filter\n",
      " --------------------------------------\n",
      "\n",
      "  set_nml_output No echo of NML values\n",
      " PE 0: initialize_mpi_utilities:  Running with            4  MPI processes.\n",
      "\n",
      " --------------------------------------------------------\n",
      " -------------- ASSIMILATE_THESE_OBS_TYPES --------------\n",
      "    TEMPERATURE\n",
      " --------------------------------------------------------\n",
      " -------------- EVALUATE_THESE_OBS_TYPES   --------------\n",
      "    none\n",
      " --------------------------------------------------------\n",
      " ---------- USE_PRECOMPUTED_FO_OBS_TYPES   --------------\n",
      "    none\n",
      " --------------------------------------------------------\n",
      "\n",
      " PE 0: quality_control_mod: Will reject obs with Data QC larger than    3\n",
      " PE 0: quality_control_mod: No observation outlier threshold rejection will be done\n",
      " PE 0: assim_tools_init: Selected filter type is Ensemble Kalman Filter (ENKF)\n",
      " PE 0: assim_tools_init: The cutoff namelist value is     1000000.000000\n",
      " PE 0: assim_tools_init: ... cutoff is the localization half-width parameter,\n",
      " PE 0: assim_tools_init: ... so the effective localization radius is     2000000.000000\n",
      " PE 0: assim_tools_init: Replicating a copy of the ensemble mean on every task\n",
      " PE 0: assim_tools_init: ... uses more memory per task but may run faster if doing vertical\n",
      " PE 0: assim_tools_init: ... coordinate conversion; controlled by namelist item \"distribute_mean\"\n",
      " PE 0: filter_main: running with an ensemble size of    40\n",
      " PE 0: parse_stages_to_write:  filter will write stage : output\n",
      " PE 0: filter_main: running with distributed state; model states stay distributed across all tasks for the entire run\n",
      "read_model_time day=2, sec=6299\n",
      "read_model_time day=2, sec=6299\n",
      "read_model_time day=2, sec=6299\n",
      "read_model_time day=2, sec=6299\n",
      " PE 0: Prior inflation: None\n",
      " PE 0: Posterior inflation: None\n",
      " PE 0: filter_main: Reading in initial condition/restart data for all ensemble members from file(s)\n",
      " PE 0:\n",
      " PE 0: filter: Main assimilation loop, starting iteration    0\n",
      " PE 0: move_ahead Next assimilation window starts    at:  day=       2 sec=  5400\n",
      " PE 0: move_ahead Next assimilation window ends      at:  day=       2 sec=  7199\n",
      " PE 0: filter: Model does not need to run; data already at required time\n",
      " PE 0: filter: Ready to assimilate up to      18 observations\n",
      " PE 0: comp_cov_factor: Standard Gaspari Cohn localization selected\n",
      " PE 0: filter_assim: Processed      18 total observations\n",
      " PE 0:\n",
      " PE 0: filter: Main assimilation loop, starting iteration    1\n",
      " PE 0: filter: No more obs to assimilate, exiting main loop\n",
      " PE 0: filter: End of main filter assimilation loop, starting cleanup\n",
      " PE 0: write_obs_seq  opening formatted observation sequence file \"obs_seq.final\"\n",
      " PE 0: write_obs_seq  closed observation sequence file \"obs_seq.final\"\n",
      "\n",
      " --------------------------------------\n",
      " Finished ... at YYYY MM DD HH MM SS = \n",
      "                 2019 10 14 20  5 18\n",
      " Program Filter\n",
      " --------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "------------------------------------------------------------\n",
      "Move the time forward ...\n",
      "\n",
      "\n",
      "\n",
      "------------------------------------------------------------\n",
      "The entire data assimilation completes!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%script bash -s \"$dart_work_dir\" \"$inputnml_file\" \"$config_file\"\n",
    "cd $1\n",
    "csh run_DART_PFLOTRAN.csh $2 $3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 927,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total time usage of running DART and PFLOTRAN is 368.320 (second): \n"
     ]
    }
   ],
   "source": [
    "end_time = time.time()\n",
    "print(\"The total time usage of running DART and PFLOTRAN is %.3f (second): \" % (end_time-start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test ```update_confignml_time.py```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 928,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update_confignml_time, inputnml_file = files_cfg[\"update_confignml_time_file\"], files_cfg[\"input_nml_file\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 929,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python $1 $2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test ```filter```\n",
    "- Run: ```filter```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 930,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter_exe = files_cfg[\"filter_exe\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 931,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cd $1\n",
    "# $2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
