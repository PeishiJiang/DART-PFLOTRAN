{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Overview\" data-toc-modified-id=\"Overview-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Overview</a></span></li><li><span><a href=\"#Configuration\" data-toc-modified-id=\"Configuration-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Configuration</a></span></li><li><span><a href=\"#PFLOTRAN-preparation-&amp;-spin-up\" data-toc-modified-id=\"PFLOTRAN-preparation-&amp;-spin-up-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>PFLOTRAN preparation &amp; spin-up</a></span><ul class=\"toc-item\"><li><span><a href=\"#Generate-PFLOTRAN.in-and-parameter.h5\" data-toc-modified-id=\"Generate-PFLOTRAN.in-and-parameter.h5-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Generate <code>PFLOTRAN.in</code> and <code>parameter.h5</code></a></span></li></ul></li><li><span><a href=\"#Model-spin-up\" data-toc-modified-id=\"Model-spin-up-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Model spin-up</a></span></li><li><span><a href=\"#DART-files-preparation\" data-toc-modified-id=\"DART-files-preparation-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>DART files preparation</a></span><ul class=\"toc-item\"><li><span><a href=\"#Generate-the-templates-for-DART-generic-variable-quantity-files\" data-toc-modified-id=\"Generate-the-templates-for-DART-generic-variable-quantity-files-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Generate the templates for DART generic variable quantity files</a></span></li><li><span><a href=\"#Generate--DART-input-namelists-in-input.nml\" data-toc-modified-id=\"Generate--DART-input-namelists-in-input.nml-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>Generate  DART input namelists in <code>input.nml</code></a></span></li><li><span><a href=\"#Generate-DART-prior-NetCDF-files-from-the-model-spin-up\" data-toc-modified-id=\"Generate-DART-prior-NetCDF-files-from-the-model-spin-up-5.3\"><span class=\"toc-item-num\">5.3&nbsp;&nbsp;</span>Generate DART prior NetCDF files from the model spin-up</a></span></li><li><span><a href=\"#Convert-observation-to-DART-observation-format\" data-toc-modified-id=\"Convert-observation-to-DART-observation-format-5.4\"><span class=\"toc-item-num\">5.4&nbsp;&nbsp;</span>Convert observation to DART observation format</a></span></li><li><span><a href=\"#Run-check_model_mod\" data-toc-modified-id=\"Run-check_model_mod-5.5\"><span class=\"toc-item-num\">5.5&nbsp;&nbsp;</span>Run <code>check_model_mod</code></a></span></li></ul></li><li><span><a href=\"#(TODO)-Run-DART-and-PFLOTRAN\" data-toc-modified-id=\"(TODO)-Run-DART-and-PFLOTRAN-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>(TODO) Run DART and PFLOTRAN</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "The **objective** of this notebook is to present the flow chart of conducting data assimilation on [PFLOTRAN](https://www.pflotran.org/) by using [DART](https://www.image.ucar.edu/DAReS/DART/). Briefly, the procedures are as follows:\n",
    "- [x] [set the configuration](#parameter): define directories, file locations, and other parameters\n",
    "- [x] [prepare PFLOTRAN simulations](#pflotran_prepare): generate PFLOTRAN input files and conduct model spin-up\n",
    "- [x]  run spin-up:\n",
    "- [x] [prepare DART files](#dart_prepare): add new DART quantities, prepare DART input namelists, prepare DART prior data, prepare observations in DART format, and check ```model_mod``` interface\n",
    "- [ ] [run DART and PFLOTRAN](#run_dart_pflotran): run the shell script for integrating DART filter and PFLOTRAN model\n",
    "\n",
    "Here, we perform inverse modeling on a 1D thermal model for illustration. The model assimilates temperature observation to update its parameters (i.e., flow flux, porosity, and thermal conductivity). For now, the ensemble Kalman filter (EnKF) is used for assimilation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='parameter'></a>\n",
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Directories\n",
    "obs_kind_dir    = '../obs_kind/'        # Directory for defining default DART generic quantity  \n",
    "obs_type_dir    = '../obs_type/'        # Directory for mapping observation variable with DART generic quantity\n",
    "utils_dir       = '../utils/'           # Directory for utility files\n",
    "work_dir        = '../work/'            # Directory for compiling and running DART files\n",
    "pflotran_in_dir = '../pflotran_input/'  # Directory for saving PFLOTRAN input files\n",
    "pflotran_out_dir= '../pflotran_output/' # Directory for saving PFLOTRAN output files\n",
    "dart_data_dir   = '../dart_inout/'      # Directory for saving DART in-out files\n",
    "\n",
    "# DART file names\n",
    "def_obs_kind   = obs_kind_dir+'DEFAULT_obs_kind_mod.f90'   # The default DART generic quantity file\n",
    "obs_type       = obs_type_dir+'obs_def_pflotran_mod.f90'   # The map between DART generic quantities and observation variables\n",
    "input_nml      = work_dir+'input.nml'                      # The input namelists used by DART programs\n",
    "input_nml_dict = work_dir+'inputnml.p'                     # The pickle file for saving input namelists in dictionary format\n",
    "\n",
    "# PFLOTRAN file names\n",
    "pflotran_sh   = utils_dir+'pflotran.sh'                                 # Script for running PFLOTRAN\n",
    "pflotran_exe  = '/Users/jian449/Codes/pflotran/src/pflotran/pflotran'   # Location of the executable PFLOTRAN file\n",
    "pflotran_in   = pflotran_in_dir+'pflotran.in'                           # PFLOTRAN input deck file\n",
    "pflotran_para = pflotran_in_dir+'parameter.h5'                          # PFLOTRAN parameter HDF file\n",
    "pflotran_out  = pflotran_out_dir+'R[ENS].h5'                            # PFLOTRAN output HDF filename template for each ensemble [ENS]\n",
    "\n",
    "# Data file names, including observations and model input/output\n",
    "obs_original = pflotran_in_dir+'temperature.csv'          # The original observation file in CSV format\n",
    "obs_nc       = pflotran_in_dir+'obs_pflotran.nc'          # The converted observation file in NetCDF format\n",
    "obs_dart     = dart_data_dir+'obs_seq_pflotran.out'       # The converted observation file in DART format\n",
    "dart_prior_nc= dart_data_dir+'prior_R[ENS].nc'            # The NetCDF filename template for DART's prior data of each ensemble [ENS]\n",
    "dart_prior_template = re.sub(r\"\\[ENS\\]\",'template',dart_prior_nc)  # The NetCDF filename for DART\n",
    "dart_input_list = dart_data_dir+\"filter_input_list.txt\"   # The list of DART prior files for all ensembles\n",
    "dart_output_list = dart_data_dir+\"filter_output_list.txt\" # The list of DART posterior files for all ensembles\n",
    "\n",
    "# Some shell scripts or executable files\n",
    "convert_nc              = work_dir+'convert_nc'           # The executable file to convert observation from NetCDF to DART formats\n",
    "compile_convert_nc      = work_dir+'dart_seq_convert.csh' # Shell script for generating the executable file to convert observation from NetCDF to DART formats\n",
    "compile_model_check_mod = work_dir+'check_model_mod.csh'  # Shell script for checking model_mod.F90 file\n",
    "run_filter              = work_dir+'run_filter.csh'       # Shell script for running DART filter and PFLOTRAN\n",
    "advance_model           = work_dir+'advance_model.csh'    # Shell script for forward simulation of PFLOTRAN\n",
    "\n",
    "# Utility file names\n",
    "csv_to_nc          = utils_dir+'csv2nc.py'                  # Python script for converting raw observation to NetCDF file\n",
    "to_dartqty         = utils_dir+'list2dartqty.py'            # Python script for reading a list of variable names and adding new DART quantities      \n",
    "prep_pflotran_in   = utils_dir+'prepare_pflotran_inpara.py' # Python script for preparing PFLOTRAN.in and parameter.h5 files\n",
    "prep_convert_nc    = utils_dir+'prepare_convert_nc.py'      # Python script for preparing convert_nc.F90 script\n",
    "prep_prior_nc      = utils_dir+'prepare_prior_nc.py'        # Python script for preparing the prior NetCDF files for DART\n",
    "prep_inputnml      = utils_dir+'prepare_input_nml.py'       # Python script for preparing the input.nml file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MPI settings\n",
    "mpi_exe = '/usr/local/bin/mpirun'  # The location of mpirun\n",
    "ncore   = 1                        # The number of MPI cores used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Data assimilation configurations\n",
    "# More need to be added...\n",
    "# And later on, these DA setting can be saved in a txt or pickel file for further loading\n",
    "# obs_timestep  = 300.0  # second\n",
    "obs_resolution  = 300.0  # second\n",
    "obs_error     = 0.1    # observation error\n",
    "spinup        = 1      # whether model spinup\n",
    "spinup_length = 0.5    # spinup time (day)\n",
    "nens          = 30     # number of ensembles\n",
    "\n",
    "# Assimilation time window time_step_days+time_step_seconds\n",
    "time_step_days    = 0   # assimilation time window/step (day)\n",
    "time_step_seconds = 600 # assimilation time window/step  (second)\n",
    "\n",
    "# Specify PFLOTRAN variables used as observation and state vector/parameters in DART\n",
    "obs_var_set = ['TEMPERATURE']\n",
    "para_set    = ['FLOW_FLUX','POROSITY','THERMAL_CONDUCTIVITY']\n",
    "# state_set   = ['LIQUID_SATURATION','LIQUID_PRESSURE', 'TEST_VARIABLE', 'TEST_VARIABLEAAA'\n",
    "pflotran_parastate_set = obs_var_set + para_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the above parameters in pickle???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='pflotran_prepare'></a>\n",
    "# PFLOTRAN preparation & spin-up\n",
    "*Here, we use Kewei's 1D thermal model as an example for generating PFLOTRAN input card and parameter.h5.*\n",
    "\n",
    "In this section, the following procedures are performed:\n",
    "- generate PFLOTRAN input deck file ```PFLOTRAN.in```\n",
    "- generate the parameter files in HDF 5, ```parameter.h5```, used by PFLOTRAN input deck file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate ```PFLOTRAN.in``` and ```parameter.h5```\n",
    "- Run: ```prepare_pflotran_inpara.py```\n",
    "- Code input arguments:\n",
    "    - <span style=\"background-color:yellow\">pflotran_in</span>: filename for ```pflotran.in```\n",
    "    - <span style=\"background-color:yellow\">pflotran_para</span>: filename for ```parameter.h5```\n",
    "    - <span style=\"background-color:yellow\">obs_resolution, obs_error, nens, spinup, spinup_length</span>: data assimilation settings (i.e., observation timestep, observation error, number of ensemble, whether it is spinup, **to be revised**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script bash -s \"$prep_pflotran_in\" \"$pflotran_in\" \"$pflotran_para\" \"$obs_resolution\" \"$obs_error\" \"$nens\" \"$spinup\" \"$spinup_length\"\n",
    "python $1 $2 $3 $4 $5 $6 $7 $8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script bash -s \"$pflotran_in\"\n",
    "head $1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model spin-up\n",
    "Take in the ```pflotran.in``` and ```parameter.h5``` files and conduct the model spin-up by running ```pflotran.sh``` file. The ```pflotran.sh``` is a simple shell script executing ensemble simulation of PFLOTRAN by using MPI.\n",
    "\n",
    "**Run the code**\n",
    "- Run: ```prepare_pflotran_inpara.py```\n",
    "- Code input arguments:\n",
    "    - <span style=\"background-color:yellow\">pflotran_exe</span>: location of the executable PFLOTRAN\n",
    "    - <span style=\"background-color:yellow\">pflotran_in</span>: filename for ```pflotran.in```\n",
    "    - <span style=\"background-color:yellow\">pflotran_out_dir</span>: directory of PFLOTRAN output\n",
    "    - <span style=\"background-color:yellow\">nens</span>: number of ensemble\n",
    "    - <span style=\"background-color:yellow\">mpi_exe, ncore</span>: location of mpirun and number of cpu cores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script bash -s \"$pflotran_sh\" \"$pflotran_exe\" \"$pflotran_in\" \"$pflotran_out_dir\" \"$nens\" \"$mpi_exe\" \"$ncore\"\n",
    "echo $3\n",
    "$1 $2 $3 $4 $5 $6 $7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script bash -s \"$pflotran_out_dir\"\n",
    "cd $1\n",
    "ls *.h5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='dart_prepare'></a>\n",
    "# DART files preparation\n",
    "In this section, the following procedures are performed:\n",
    "- generate the template for DART generic variable quantity files (i.e., ```DEFAULT_obs_kind_mod.F90``` and ```obs_def_pflotran_mod.f90```);\n",
    "- generate the DART input namelists;\n",
    "- generate DART prior NetCDF data ```prior_R[ENS].nc``` from PFLOTRAN's parameter and outputs;\n",
    "- convert the observation file to DART observation format;\n",
    "- check ```model_mod.F90``` based on current setting by using the ```check_model_mod``` provided by DART."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the templates for DART generic variable quantity files\n",
    "- Run: ```list2dartqty.py``` to sequentially generate\n",
    "    - a mapping between PFLOTRAN variales and DART generic quantities in ```obs_def_pflotran_mod.F90```\n",
    "    - the default DART generic quantity definition file ```DEFAULT_obs_kind_mod.F90```\n",
    "- Code input arguments:\n",
    "    - <span style=\"background-color:yellow\">obs_type</span>: filename for ```DEFAULT_obs_kind_mod.F90```\n",
    "    - <span style=\"background-color:yellow\">def_obs_kind</span>: filename for ```obs_def_pflotran_mod.F90```\n",
    "    - <span style=\"background-color:yellow\">pflotran_parastate_set</span>: a list of variables required to be assimilated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script bash -s \"$to_dartqty\" \"$obs_type\" \"$def_obs_kind\" \"$pflotran_parastate_set\"\n",
    "python $1 $2 $3 $4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script bash -s \"$obs_type\"\n",
    "cat $1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate  DART input namelists in ```input.nml```\n",
    "\n",
    "The ```input.nml``` file is generated based on a template ```input.nml.template``` by modifying the following namelist entries:\n",
    "\n",
    "```input.nml.template``` $\\rightarrow$ ```input.nml```\n",
    "\n",
    "|filter_nml|obs_kind_nml|preprocess_nml|model_nml|convertnc_nml|\n",
    "|:--:|:--:|:--:|:--:|:--:|\n",
    "| input_state_file_list, output_state_file_list, ens_size, async, adv_ens_command, obs_sequence_in_name | assimilate_these_obs_types | input_files, input_obs_kind_mod_file | time_step_days, time_step_seconds, nvar, var_names, template_file, var_qtynames | netcdf_file, out_file |\n",
    "\n",
    "**Namelists from DART**\n",
    "- [filter_nml](https://www.image.ucar.edu/DAReS/DART/Manhattan/assimilation_code/modules/assimilation/filter_mod.html): namelist of the main module for driving ensemble filter assimilations\n",
    "- [obs_kind_nml](https://www.image.ucar.edu/DAReS/DART/Manhattan/assimilation_code/modules/observations/obs_kind_mod.html#Namelist): namelist for controling what observation types are to be assimilated\n",
    "- [preprocess_nml](https://www.image.ucar.edu/DAReS/Codes/DART/manhattan/assimilation_code/programs/preprocess/preprocess): namelist of the DART-supplied preprocessor program which creates observation kind and observation definition modules from a set of other specially formatted Fortran 90 files\n",
    "\n",
    "**Self-defined namelists**\n",
    "- model_nml: a self-defined namelist for providing the basic information in the model\n",
    "    - time_step_days, time_step_seconds: the assimilation time window\n",
    "    - template_file: the template prior NetCDF file for ```model_mod.F90``` to digest the spatial information of the model\n",
    "    - var_names: the original variable names\n",
    "    - var_qtynames: the corresponding DART variable quantities\n",
    "    - nvar: the number of variables\n",
    "- convertnc_nml: a self-defined namelist for providing the NetCDF observation file name and the DART observation file name used in ```convert_nc.f90```\n",
    "    - netcdf_file: the location of the NetCDF file containing the observation data\n",
    "    - out_file: the location of the DART observation file\n",
    "\n",
    "**Note that**\n",
    "- There are more namelists or other items in the above namelist in input.nml.template. Users can edit the below python dictionary ```inputnml``` to include their modifications.\n",
    "- Users can also include more namelists provided by DART by modifying ```inputnml```."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***************\n",
    "Assemble all the namelists in input.nml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Parameters for different namelists in input.nml\n",
    "filter_nml = {\"input_state_file_list\":dart_input_list,\n",
    "              \"output_state_file_list\":dart_output_list,\n",
    "              \"ens_size\":nens,\n",
    "              \"async\":2,\n",
    "              \"adv_ens_command\":advance_model,\n",
    "              \"obs_sequence_in_name\":obs_dart}\n",
    "obs_kind_nml = {\"assimilate_these_obs_types\":obs_var_set}\n",
    "model_nml = {\"time_step_days\":time_step_days,\n",
    "             \"time_step_seconds\":time_step_seconds,\n",
    "             \"nvar\":len(pflotran_parastate_set),\n",
    "             \"var_names\":pflotran_parastate_set,\n",
    "             \"template_file\":dart_prior_template,\n",
    "             \"var_qtynames\":['QTY_PFLOTRAN_'+v for v in pflotran_parastate_set]}\n",
    "preprocess_nml = {\"input_files\":obs_type,\n",
    "                  \"input_obs_kind_mod_file\":def_obs_kind}\n",
    "convertnc_nml = {\"netcdf_file\": obs_nc,\n",
    "                 \"out_file\": obs_dart}\n",
    "inputnml = {\"filter_nml\":filter_nml,\n",
    "            \"obs_kind_nml\":obs_kind_nml,\n",
    "            \"model_nml\":model_nml,\n",
    "            \"preprocess_nml\":preprocess_nml,\n",
    "            \"convertnc_nml\":convertnc_nml}\n",
    "\n",
    "# Save it in a temperory pickle file\n",
    "with open(input_nml_dict, 'wb') as f:\n",
    "    pickle.dump(inputnml, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***************\n",
    "- Run: ```prepare_inputnml.py```\n",
    "- Code input arguments:\n",
    "    - <span style=\"background-color:yellow\">input_nml</span>: the ```input.nml``` namelist file\n",
    "    - <span style=\"background-color:yellow\">input_nml_dict</span>: the ```inputnml.p``` pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%script bash -s  \"$prep_inputnml\" \"$input_nml\" \"$input_nml_dict\"\n",
    "python $1 $2 $3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate DART prior NetCDF files from the model spin-up\n",
    "- The structure of ```prior_R[ENS].nc``` file (```[ENS]``` refers to the ensemble number):\n",
    "\n",
    "| NetCDF dimensions |                      NetCDF variables                      |\n",
    "|:-----------------:|:----------------------------------------------------------:|\n",
    "| time: 1           | time: shape(time)                                          |\n",
    "| x_location: nx    | x_location: shape(x_location)                              |\n",
    "| y_location: ny    | y_location: shape(y_location)                              |\n",
    "| z_location: nz    | z_location: shape(z_location)                              |\n",
    "| member: 1         | member: shape(member)                                      |\n",
    "|                   | physical variable: shape(x_location,y_location,z_location) |\n",
    "\n",
    "**Note that** \n",
    "- required by DART, each ```prior_R[ENS].nc``` file only includes the state/parameter values of one ensemble member at one given time. \n",
    "- For the time, we set the initial time as 0, with time units converted *day* (requied by DART's ```read_model_time``` subroutine). \n",
    "- Also, it is different from the definition for the [observation NetCDF](#observationconvertion), because ```prior_R[ENS].nc``` aims for the structured cartesian grids while the observation NetCDF aims for a general case.\n",
    "\n",
    "**Run the code**\n",
    "- Run: ```prepare_prior_nc.py``` to generate \n",
    "    - the prior input file ```prior_R[ENS].nc``` used by DART\n",
    "    - the prior template file (copied from ```prior_R1.nc```) used by ```input.nml```\n",
    "- Code input arguments:\n",
    "    - <span style=\"background-color:yellow\">pflotran_out</span>: filename ```R[ENS].h5``` from PFLOTRAN model output\n",
    "    - <span style=\"background-color:yellow\">pflotran_para</span>: pflotran parameter HDF file ```parameter.h5```\n",
    "    - <span style=\"background-color:yellow\">dart_prior_nc</span>: filename ```prior_R[ENS].nc``` for the prior input file for DART\n",
    "    - <span style=\"background-color:yellow\">dart_input_list</span>: filename for recording the list of dart_prior_nc\n",
    "    - <span style=\"background-color:yellow\">nens</span>: number of ensemble\n",
    "    - <span style=\"background-color:yellow\">spinup</span>: whether it is spinup (if yes, the time is set to zero; otherwise, the time is read from ```R[ENS].h5```)\n",
    "    - <span style=\"background-color:yellow\">pflotran_parastate_set</span>: a list of variables to be assimilated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script bash -s \"$prep_prior_nc\" \"$pflotran_out\" \"$pflotran_para\" \"$dart_prior_nc\" \"$dart_input_list\" \"$nens\" \"$spinup\" \"$pflotran_parastate_set\"\n",
    "python $1 $2 $3 $4 $5 $6 $7 $8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script bash -s \"$dart_prior_template\"\n",
    "ncdump -h $1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='observationconvertion'></a>\n",
    "## Convert observation to DART observation format\n",
    "In this section, the observation data is converted in DART format. We first convert observation data in raw format into NetCDF format. Then, the observation file is converted into DART format. The structure of NetCDF file for recording observation file.\n",
    "\n",
    "| NetCDF dimensions |           NetCDF variables          |\n",
    "|:-----------------:|:-----------------------------------:|\n",
    "| time: 1           | time: shape(time)                   |\n",
    "| location: nloc    | location: shape(location)           |\n",
    "|                   | physical variable: shape(time,nloc) |\n",
    "\n",
    "**Note that** \n",
    "- if the time calendar follows *gregorian*, the time unit should be entered as ```seconds since YYYY-MM-DD HH:MM:SS```. Otherwise, put the time calender as *None* and time unit as ```second``` (make sure convert your measurement times to seconds)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***************\n",
    "- Run: ```csv2nc.py``` to convert the raw csv temperature observations to NetCDF file\n",
    "- Code input arguments:\n",
    "    - <span style=\"background-color:yellow\">obs_original</span>: filename for the original observed temperature file\n",
    "    - <span style=\"background-color:yellow\">obs_nc</span>: filename for the observation NetCDF file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script bash -s \"$csv_to_nc\" \"$obs_original\" \"$obs_nc\"\n",
    "python $1 $2 $3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script bash -s \"$obs_nc\"\n",
    "ncdump -h $1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***************\n",
    "- Run: ```prepare_convert_nc.py``` to prepare the ```convert_nc.f90``` based on the list of observation variables.\n",
    "- Code input arguments:\n",
    "    - <span style=\"background-color:yellow\">obs_nc</span>: filename for the observation NetCDF file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script bash -s \"$prep_convert_nc\" \"$obs_nc\"\n",
    "python $1 $2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script bash -s \"$utils_dir\"\n",
    "cd $1\n",
    "head convert_nc.f90"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***************\n",
    "- Run shell script: ```dart_seq_convert.csh``` to \n",
    "    - preprocess the DART generic variable quantity files prepared by the previous section \n",
    "    - generate an executable file for converting observation file in NetCDF format to DART format used by the next section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script bash -s \"$work_dir\" \"$compile_convert_nc\"\n",
    "cd $1\n",
    "csh $2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***************\n",
    "- Run: ```convert_nc``` to convert the observation file in NetCDF to DART format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script bash -s \"$work_dir\" \"$convert_nc\"\n",
    "cd $1\n",
    "$2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script bash -s \"$obs_dart\"\n",
    "head -n21 $1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run ```check_model_mod```\n",
    "- Run shell script: ```check_model_mod.csh``` to check the model_mod.F90 interface. See details of this mod in [link](https://www.image.ucar.edu/DAReS/DART/Manhattan/assimilation_code/programs/model_mod_check/model_mod_check.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script bash -s \"$work_dir\" \"$compile_model_check_mod\"\n",
    "cd $1\n",
    "csh $2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='run_dart_pflotran'></a>\n",
    "# (TODO) Run DART and PFLOTRAN\n",
    "In this section, run the shell script to couple DART and PFLOTRAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%script bash -s \"$work_dir\" \"$run_filter\"\n",
    "# cd $1\n",
    "# csh $2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "261.818px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 122.712818,
   "position": {
    "height": "40px",
    "left": "1066.08px",
    "right": "20px",
    "top": "82px",
    "width": "250px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
